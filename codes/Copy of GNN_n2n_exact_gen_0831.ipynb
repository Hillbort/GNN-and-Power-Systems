{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of GNN_n2n_exact_gen_0831_copy.ipynb",
   "provenance": [
    {
     "file_id": "1yH55jcqo2EZ9wVWSiPdFfxyqbMTDEEpC",
     "timestamp": 1599494521560
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-87b2824",
   "language": "python",
   "display_name": "PyCharm (GNN-for-DC-OPF)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ1P8LLwoCB-",
    "colab_type": "text"
   },
   "source": [
    "# GNN for Optimal Generation Dispatch\n",
    "## IEEE 24-bus RTS system \n",
    "* System settings: 24 buses, 34 lines (concatenated from 38), 17 loads, 12 generating units on 10 buses.\n",
    "* Data: Currently we use a dataset with ~ 6000 samples, 80% used for training and 20% for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOjKm_RBoCCA",
    "colab_type": "text"
   },
   "source": [
    "Step 1: Creating a graph in DGL\n",
    "-------------------------------\n",
    "* Load necessary packages.\n",
    "* Read the data and create the graph for the system:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Check module 'dgl' is installed, if not, install the module\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "required = {'dgl'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "\n",
    "# !pip install dgl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import dgl # graph convolution\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from dgl.nn.pytorch.conv import GraphConv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RamArMRLoCC7",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495155465,
     "user_tz": 300,
     "elapsed": 2753,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    }
   },
   "source": [
    "# Load the data files\n",
    "\n",
    "## @ G-drive env\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# filename = './drive/My Drive/Colab Notebooks/ieee24_rts_6183exact_0831.txt' # active level 0.1024(line0.0124), max active line 3\n",
    "\n",
    "## @ Local env\n",
    "filename = '../data/ieee24_rts_6183exact_0831.txt' # active level 0.1024(line0.0124), max active line 3\n",
    "\n",
    "data = pd.read_table(filename,sep=',',header=None).to_numpy()\n",
    "\n",
    "# system size\n",
    "n_bus  = int(data[0,0].copy())\n",
    "n_line  = int(data[1,0].copy())\n",
    "n_load  = int(data[2,0].copy())\n",
    "n_sample  = int(data[3,0].copy())\n",
    "\n",
    "# line connection\n",
    "line_bus = data[:,1:3].copy()\n",
    "\n",
    "# load and corresponding line data\n",
    "load_data0 = data[:,3:n_sample+3].copy()\n",
    "line_flow = data[:,n_sample + 3 : 2*n_sample + 3].copy()\n",
    "bound_idx_low = data[:,2*n_sample + 3 : 3*n_sample + 3].copy()\n",
    "bound_idx_up = data[:,3*n_sample + 3 : 4*n_sample + 3].copy()\n",
    "bound_idx0 = bound_idx_up + bound_idx_low # may use 'np.add(a,-b)' instead\n",
    "line_limit = data[:,4*n_sample + 3].copy()\n",
    "# print(line_limit)\n",
    "\n",
    "# generation data\n",
    "gen_exact = data[:,4*n_sample + 4 : 5*n_sample + 4].copy()\n",
    "gen_low_limit = data[:,5*n_sample + 4].copy()\n",
    "gen_up_limit = data[:,5*n_sample + 5].copy()\n",
    "\n",
    "# normalize the generation data\n",
    "y0 = np.zeros((n_bus,n_sample))\n",
    "for i in range(n_sample):\n",
    "  # y0[:,i] = np.divide(line_flow[:,i],line_limit) # w/ direction\n",
    "  for j in range(n_bus):\n",
    "    if gen_up_limit[j] > 0:\n",
    "      y0[j,i] = np.divide(gen_exact[j,i]-gen_low_limit[j],gen_up_limit[j]-gen_low_limit[j])\n",
    "    else:\n",
    "      y0[j,i] = 0\n",
    "\n",
    "  \n",
    "\n",
    "# % exact generation\n",
    "# data1(1:N,4*n+5:5*n+4) = gen_data;\n",
    "# % generation lower bound & upper bound\n",
    "# data1(1:N,5*n+5) = g_min;\n",
    "# data1(1:N,5*n+6) = g_max;\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WzgofvUMT1G-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495157503,
     "user_tz": 300,
     "elapsed": 318,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "7dc1636c-d514-45a5-d81e-3e21a9b8ee18"
   },
   "source": [
    "print(np.max(y0)) # check the normalization\n",
    "print(np.min(y0))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yfMmqGJmru9O",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495159819,
     "user_tz": 300,
     "elapsed": 461,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "1470369a-dc8d-4108-f259-a6ffa985b231"
   },
   "source": [
    "# Use partial data for faster test\n",
    "n_sample = 6000\n",
    "\n",
    "load_data = load_data0[:,:n_sample].copy()\n",
    "bound_idx = bound_idx0[:,:n_sample].copy()*1\n",
    "\n",
    "# gen_idx_low = gen_idx_low[:,:n_sample]\n",
    "# gen_idx_up = gen_idx_up[:,:n_sample]\n",
    "# gen_idx = gen_idx_up + gen_idx_low\n",
    "\n",
    "# print system info\n",
    "print('Test case: ',filename)\n",
    "print('Number of buses: ',n_bus)\n",
    "print('Number of lines: ',n_line)\n",
    "print('Number of loads: ',n_load)\n",
    "print('Number of samples: ',n_sample)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case:  ../data/ieee24_rts_6183exact_0831.txt\n",
      "Number of buses:  24\n",
      "Number of lines:  34\n",
      "Number of loads:  17\n",
      "Number of samples:  6000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf9YAQgToCEO",
    "colab_type": "text"
   },
   "source": [
    "* Generate and visualize the DGL graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NxaGvjWGoCEH",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495162760,
     "user_tz": 300,
     "elapsed": 708,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    }
   },
   "source": [
    "# Graph generating function\n",
    "def build_system_graph(src,dst):\n",
    "    # Edges are directional in DGL; Make them bi-directional.\n",
    "    # Matlab counts from 1 and python from 0\n",
    "    u = np.concatenate([src, dst])-1 \n",
    "    v = np.concatenate([dst, src])-1\n",
    "    # Construct a DGLGraph\n",
    "    return dgl.DGLGraph((u, v))"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H3zws2wBoCEd",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495163662,
     "user_tz": 300,
     "elapsed": 365,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "7710c6dc-932e-40f1-b648-eca13c837273"
   },
   "source": [
    "line_src = line_bus[:,0].copy().astype(int)\n",
    "line_dst = line_bus[:,1].copy().astype(int)\n",
    "G = build_system_graph(line_src,line_dst)\n",
    "print('There are %d nodes.' % G.number_of_nodes())\n",
    "print('There are %d edges.' % G.number_of_edges())\n",
    "\n",
    "import networkx as nx\n",
    "# Since the actual graph is undirected, we convert it for visualization\n",
    "# purpose.\n",
    "# nx_G = G.to_networkx().to_undirected()\n",
    "# # Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n",
    "# pos = nx.kamada_kawai_layout(nx_G)\n",
    "# nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 nodes.\n",
      "There are 68 edges.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeehyunpark/anaconda3/envs/GNN4OPF/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLmJ64bCoCFJ",
    "colab_type": "text"
   },
   "source": [
    "Step 2: Assign features to nodes, edges\n",
    "--------------------------------------------\n",
    "e.g.: Graph neural networks associate features with nodes and edges for training.\n",
    "\n",
    "* In our case, inputs on nodes, features on egdes\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7xqplmGwoCFe",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495166537,
     "user_tz": 300,
     "elapsed": 308,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    }
   },
   "source": [
    "# # In DGL, you can add features for all nodes at once, using a feature tensor that\n",
    "# # batches node features along the first dimension. The code below adds the learnable\n",
    "# # embeddings for all nodes:\n",
    "\n",
    "# embed_feature = 10\n",
    "# embed = nn.Embedding(G.number_of_edges(), embed_feature)  \n",
    "# # 68 edges with embedding dim equal to 10 for edge classification\n",
    "# G.edata['feat'] = embed.weight"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHOzg-9PoCF3",
    "colab_type": "text"
   },
   "source": [
    "Step 3: Define a Graph Convolutional Network (GCN) and Train the model\n",
    "--------------------------------------------------\n",
    "To perform node classification, use the Graph Convolutional Network\n",
    "(GCN) developed by `Kipf and Welling <https://arxiv.org/abs/1609.02907>`_. Here\n",
    "is the simplest definition of a GCN framework. We recommend that you \n",
    "read the original paper for more details.\n",
    "\n",
    "- At layer $l$, each node $v_i^l$ carries a feature vector $h_i^l$.\n",
    "- Each layer of the GCN tries to aggregate the features from $u_i^{l}$ where\n",
    "  $u_i$'s are neighborhood nodes to $v$ into the next layer representation at\n",
    "  $v_i^{l+1}$. This is followed by an affine transformation with some\n",
    "  non-linearity.\n",
    "\n",
    " **In this project we use weighted graph convolution and weights are \n",
    "learned during the trainning process.**\n",
    "\n",
    "The above definition of GCN fits into a **message-passing** paradigm: Each\n",
    "node will update its own feature with information sent from neighboring\n",
    "nodes. A graphical demonstration is displayed below.\n",
    "\n",
    "\n",
    "In DGL, we provide implementations of popular Graph Neural Network layers under\n",
    "the `dgl.<backend>.nn` subpackage. The :class:`~dgl.nn.pytorch.GraphConv` module\n",
    "implements one Graph Convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBIgnqqtoCGB",
    "colab_type": "text"
   },
   "source": [
    "**In our case, we want to perform edge classification based on feature inputs from nodes.**\n",
    "* Thus we need to redesign the GNN to map the features from node to deges\n",
    "* Define a deeper GCN model that contains two GCN layers:\n",
    "\n",
    "We first try convolutions on the nodes first then map to edges then try mapping to edges first then do convolutions on edges"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J2fkZxWsoCGP",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495170106,
     "user_tz": 300,
     "elapsed": 361,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    }
   },
   "source": [
    "# One layer Graph convolution from nodes to edges\n",
    "class Graph_convolution_v2e(nn.Module):\n",
    "    def __init__(self,in_features,out_features,W,bias=True):\n",
    "        super(Graph_convolution_v2e,self).__init__()\n",
    "#         self.Weight=nn.Parameter(torch.Tensor(W))\n",
    "#         self.Weight=nn.Parameter(torch.from_numpy(W))\n",
    "        self.register_buffer('w',torch.from_numpy(W).float())\n",
    "#         for temp in self.Weight:\n",
    "#             temp.requires_grad=False\n",
    "#         self.Weight = self.Weight.detach()\n",
    "        self.scale=nn.Parameter(torch.Tensor(out_features,1))\n",
    "        self.bias=nn.Parameter(torch.Tensor(out_features,1))\n",
    "    \n",
    "    def forward(self,input):\n",
    "        # print(input.shape)\n",
    "        # print(self.scale.shape)  \n",
    "        h = torch.matmul(Variable(self.w),input) \n",
    "        return torch.mul(h,self.scale) + self.bias   \n",
    "\n",
    "# Need to change that to our case: 2 networks, one node clustering (or double it as in the reference), \n",
    "# one node to edge.\n",
    "\n",
    "# Set dummy bus signals as zero\n",
    "I_bus = np.identity(n_bus)\n",
    "idx = [2,3,4,5,7,8,9,10,11,16,18,19,23]\n",
    "for i in range(len(idx)):\n",
    "  I_bus[idx,idx] = 0\n",
    "I_bus = torch.from_numpy(I_bus).float()\n",
    "\n",
    "# GNN using DGL v2v graph convolution and our own v2e graph convolution\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_nodes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size[0],norm='both', weight=True, bias=True, activation=None) \n",
    "        #norm='both', weight=True, bias=True, activation=None\n",
    "        self.conv2 = GraphConv(hidden_size[0], hidden_size[1],norm='both', weight=True, bias=True, activation=None)\n",
    "        self.conv3 = GraphConv(hidden_size[1], hidden_size[2],norm='both', weight=True, bias=True, activation=None)\n",
    "        self.conv4 = GraphConv(hidden_size[2], hidden_size[3],norm='both', weight=True, bias=True, activation=None)\n",
    "        self.conv5 = GraphConv(hidden_size[3], hidden_size[4],norm='both', weight=True, bias=True, activation=None)\n",
    "        self.conv6 = GraphConv(hidden_size[4], hidden_size[5],norm='both', weight=True, bias=True, activation=None)\n",
    "        # self.conv7 = GraphConv(hidden_size[5], hidden_size[6],norm='both', weight=True, bias=True, activation=None)\n",
    "        # self.conv8 = GraphConv(hidden_size[6], hidden_size[7],norm='both', weight=True, bias=True, activation=None)\n",
    "        # self.conv9 = GraphConv(hidden_size[7], hidden_size[8],norm='both', weight=True, bias=True, activation=None)\n",
    "        # self.conv3 = Graph_convolution_v2e(hidden_size[1], num_edges, W)\n",
    "#         self.W = W\n",
    "\n",
    "        self.lin_output = nn.Linear(num_nodes,num_nodes)\n",
    "\n",
    "    def forward(self, g, I, inputs): # g is the graph stored in DGL\n",
    "        # print(g) \n",
    "        # nx_G = g.to_networkx().to_undirected()\n",
    "        # pos = nx.kamada_kawai_layout(nx_G)\n",
    "        # nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])      \n",
    "        # print('inputs data type:', inputs.data.type())\n",
    "        # print(inputs.shape)\n",
    "        h = self.conv1(g, inputs)\n",
    "        # h = torch.sigmoid(h)\n",
    "        # print(h.shape)\n",
    "        h = self.conv2(g, h)\n",
    "        # print(h.shape)\n",
    "        h = torch.sigmoid(h)\n",
    "        # print(h.shape)\n",
    "        h = self.conv3(g, h)\n",
    "        # h = torch.sigmoid(h)\n",
    "        h = self.conv4(g, h)\n",
    "        h = torch.sigmoid(h) \n",
    "        h = self.conv5(g, h)\n",
    "        # h = torch.sigmoid(h)\n",
    "        h = self.conv6(g, h)\n",
    "        h = torch.sigmoid(h)\n",
    "        # h = self.conv7(g, h)\n",
    "        # # h = torch.sigmoid(h)\n",
    "        # h = self.conv8(g, h)\n",
    "        # h = torch.sigmoid(h)\n",
    "        # h = self.conv9(g, h)\n",
    "        # h = torch.sigmoid(h)\n",
    "        # h = self.conv3(h)\n",
    "        # h = torch.matmul(I,h)\n",
    "        h = self.lin_output(h.transpose(0,1)).transpose(0,1)\n",
    "        # h = torch.matmul(I,h)\n",
    "        return h\n",
    "\n",
    " \n",
    "# net = GCN_self(n_bus, [10,10], n_line, W, W1)\n",
    "# net = GCN(n_bus, [10,10,10,10,10,10,10,1], n_line, W1)\n",
    "w_params = [40,80,80,80,80,1]\n",
    "net = GCN(1, w_params, n_bus)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y_cb_xqOj9bq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495178592,
     "user_tz": 300,
     "elapsed": 378,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "1e49d6fd-5dc9-4533-cabe-cbd9a2faf5b4"
   },
   "source": [
    "net"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "GCN(\n  (conv1): GraphConv(in=1, out=40, normalization=both, activation=None)\n  (conv2): GraphConv(in=40, out=80, normalization=both, activation=None)\n  (conv3): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv4): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv5): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv6): GraphConv(in=80, out=1, normalization=both, activation=None)\n  (lin_output): Linear(in_features=24, out_features=24, bias=True)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mpNqT4YmoCGg",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495181187,
     "user_tz": 300,
     "elapsed": 306,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "2992762c-a4cc-4f3e-c7d6-98662cc3927f"
   },
   "source": [
    "# Set the ratio of training/test set\n",
    "train_ratio = 0.8\n",
    "n_train = int(np.floor(train_ratio * n_sample))\n",
    "n_test = n_sample - n_train\n",
    "print('Data set size: ',n_sample,', training set size: ',n_train,', test set size: ',n_test)\n",
    "\n",
    "# Generate training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(load_data[0:n_bus,:].transpose(), y0[:,0:n_sample].transpose(), test_size=0.2, random_state=22)\n",
    "x_train = x_train2.transpose()\n",
    "y_train = y_train2.transpose()\n",
    "x_test = x_test2.transpose()\n",
    "y_test = y_test2.transpose()\n",
    "# x_train = load_data[0:n_bus,0:n_train].copy()\n",
    "# y_train = bound_idx[:,0:n_train].copy()\n",
    "# x_test = load_data[0:n_bus,n_train:n_sample].copy()\n",
    "# y_test = bound_idx[:,n_train:n_sample].copy()\n",
    "\n",
    "\n",
    "tempx=np.array([np.transpose(x_train)[0]])\n",
    "x_train_one=torch.from_numpy(tempx).float()\n",
    "x_train_one=x_train_one.transpose(0,1)\n",
    "print(x_train_one.shape)\n",
    "\n",
    "\n",
    "tempy=np.array([np.transpose(y_train)[0]])\n",
    "y_train_one=torch.from_numpy(tempy).float()\n",
    "y_train_one=y_train_one.transpose(0,1)\n",
    "print(y_train_one.shape)\n",
    "# print('Training data size:',x_train.shape)\n",
    "# print('Training label size:',y_train.shape)\n",
    "\n",
    "# get the training data for DGL\n",
    "def get_xy(index):\n",
    "    tempx=np.array([np.transpose(x_train)[index]])\n",
    "    x_train_one=torch.from_numpy(tempx).float()\n",
    "    x_train_one=x_train_one.transpose(0,1)\n",
    "\n",
    "    tempy=np.array([np.transpose(y_train)[index]])\n",
    "    y_train_one=torch.from_numpy(tempy).float()\n",
    "    y_train_one=y_train_one.transpose(0,1)\n",
    "\n",
    "    return x_train_one,y_train_one\n",
    "\n",
    "# generate torch y_train for concatenated obj\n",
    "y_train1 = torch.from_numpy(y_train)#.float()\n",
    "# expand into 3d tensor \n",
    "y_train1.unsqueeze_(-1)\n",
    "y_train1 = y_train1.expand(n_bus,n_train,1)\n",
    "y_train1 = y_train1.transpose(2,1)\n",
    "print(y_train1.shape)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size:  6000 , training set size:  4800 , test set size:  1200\n",
      "torch.Size([24, 1])\n",
      "torch.Size([24, 1])\n",
      "torch.Size([24, 1, 4800])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vYRy5jCOpg7m",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599495183815,
     "user_tz": 300,
     "elapsed": 325,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "1188e783-4bb7-4266-d2ee-7cfbd56a37e9"
   },
   "source": [
    "# GNN model size\n",
    "print('Network info:',net)\n",
    "for temp in net.parameters():\n",
    "    print('Parameter',temp,'size:',temp.shape)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network info: GCN(\n",
      "  (conv1): GraphConv(in=1, out=40, normalization=both, activation=None)\n",
      "  (conv2): GraphConv(in=40, out=80, normalization=both, activation=None)\n",
      "  (conv3): GraphConv(in=80, out=80, normalization=both, activation=None)\n",
      "  (conv4): GraphConv(in=80, out=80, normalization=both, activation=None)\n",
      "  (conv5): GraphConv(in=80, out=80, normalization=both, activation=None)\n",
      "  (conv6): GraphConv(in=80, out=1, normalization=both, activation=None)\n",
      "  (lin_output): Linear(in_features=24, out_features=24, bias=True)\n",
      ")\n",
      "Parameter Parameter containing:\n",
      "tensor([[ 1.6685e-01, -3.3306e-01,  3.4409e-01,  3.3748e-01, -3.7415e-01,\n",
      "          1.5664e-01,  6.6524e-02,  3.3697e-04, -2.9730e-01,  6.0916e-02,\n",
      "          4.9961e-02,  3.5847e-02, -3.0070e-01,  3.2523e-01,  1.1745e-01,\n",
      "          3.1368e-01, -1.6137e-01, -1.4224e-01, -1.4343e-01, -3.5827e-01,\n",
      "         -9.2137e-02,  4.4945e-03, -3.6912e-01, -3.5111e-01, -1.5674e-01,\n",
      "          2.3207e-01,  2.3458e-01, -1.4899e-01,  3.5495e-01, -2.3311e-01,\n",
      "          2.6601e-01, -2.8812e-02, -3.1439e-01, -2.1907e-02, -2.0011e-01,\n",
      "          2.8370e-01,  3.5515e-01,  2.9201e-01,  2.9785e-01, -1.4404e-01]],\n",
      "       requires_grad=True) size: torch.Size([1, 40])\n",
      "Parameter Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True) size: torch.Size([40])\n",
      "Parameter Parameter containing:\n",
      "tensor([[-0.0737, -0.0621,  0.0216,  ..., -0.1879,  0.1428,  0.2015],\n",
      "        [-0.1069,  0.0379,  0.1372,  ..., -0.1000,  0.0724, -0.0362],\n",
      "        [ 0.0503,  0.0509,  0.0882,  ..., -0.0266,  0.0079,  0.0920],\n",
      "        ...,\n",
      "        [ 0.1285,  0.0734,  0.1924,  ..., -0.0425, -0.1713, -0.0436],\n",
      "        [-0.1577, -0.0523, -0.1138,  ..., -0.0016,  0.1692, -0.1685],\n",
      "        [-0.0859,  0.0537, -0.1047,  ..., -0.0302, -0.1147,  0.1293]],\n",
      "       requires_grad=True) size: torch.Size([40, 80])\n",
      "Parameter Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True) size: torch.Size([80])\n",
      "Parameter Parameter containing:\n",
      "tensor([[ 0.0091, -0.1412, -0.1673,  ..., -0.1616, -0.1151,  0.1249],\n",
      "        [ 0.0399,  0.0220,  0.1713,  ..., -0.1145, -0.0740, -0.1154],\n",
      "        [ 0.1459, -0.1812,  0.1101,  ..., -0.1911, -0.0388, -0.0910],\n",
      "        ...,\n",
      "        [ 0.0340, -0.0682,  0.0457,  ..., -0.0745, -0.0932, -0.1344],\n",
      "        [ 0.0571,  0.0254,  0.1526,  ..., -0.0518,  0.0760, -0.1367],\n",
      "        [ 0.0655, -0.1807, -0.1045,  ..., -0.1424,  0.0533, -0.1766]],\n",
      "       requires_grad=True) size: torch.Size([80, 80])\n",
      "Parameter Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True) size: torch.Size([80])\n",
      "Parameter Parameter containing:\n",
      "tensor([[-0.0417,  0.0048,  0.1855,  ..., -0.1012, -0.0115, -0.1343],\n",
      "        [ 0.0546, -0.1763, -0.0462,  ...,  0.1105,  0.1338,  0.0700],\n",
      "        [-0.0640, -0.0539, -0.0495,  ..., -0.1443, -0.0608,  0.1532],\n",
      "        ...,\n",
      "        [-0.0079, -0.1247, -0.0255,  ..., -0.1477,  0.0412, -0.0142],\n",
      "        [ 0.0455,  0.1333, -0.0357,  ...,  0.0771,  0.0977, -0.1865],\n",
      "        [ 0.0347, -0.1326,  0.0065,  ..., -0.0115,  0.1127,  0.0466]],\n",
      "       requires_grad=True) size: torch.Size([80, 80])\n",
      "Parameter Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True) size: torch.Size([80])\n",
      "Parameter Parameter containing:\n",
      "tensor([[ 0.0705, -0.0690,  0.0852,  ...,  0.0968,  0.1417, -0.1556],\n",
      "        [ 0.1712, -0.0106, -0.1766,  ..., -0.1672,  0.1091, -0.0934],\n",
      "        [-0.0949,  0.1531,  0.1777,  ..., -0.1134, -0.1007,  0.0635],\n",
      "        ...,\n",
      "        [ 0.0753,  0.1371,  0.1766,  ...,  0.1820, -0.1470, -0.1003],\n",
      "        [ 0.1033, -0.0838,  0.1174,  ...,  0.1491, -0.1644,  0.0538],\n",
      "        [ 0.0205, -0.0709,  0.1878,  ...,  0.0042, -0.0624, -0.1434]],\n",
      "       requires_grad=True) size: torch.Size([80, 80])\n",
      "Parameter Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True) size: torch.Size([80])\n",
      "Parameter Parameter containing:\n",
      "tensor([[-0.0855],\n",
      "        [-0.1680],\n",
      "        [-0.1704],\n",
      "        [ 0.1400],\n",
      "        [-0.2208],\n",
      "        [-0.1417],\n",
      "        [ 0.1623],\n",
      "        [-0.0385],\n",
      "        [-0.1849],\n",
      "        [ 0.1356],\n",
      "        [ 0.0905],\n",
      "        [ 0.0918],\n",
      "        [ 0.0047],\n",
      "        [-0.1003],\n",
      "        [ 0.2005],\n",
      "        [ 0.1510],\n",
      "        [ 0.0478],\n",
      "        [-0.0848],\n",
      "        [-0.0679],\n",
      "        [ 0.2339],\n",
      "        [-0.1643],\n",
      "        [ 0.1332],\n",
      "        [ 0.1418],\n",
      "        [ 0.1735],\n",
      "        [ 0.0168],\n",
      "        [ 0.1932],\n",
      "        [ 0.1002],\n",
      "        [ 0.0091],\n",
      "        [ 0.2588],\n",
      "        [ 0.0280],\n",
      "        [-0.2632],\n",
      "        [ 0.0070],\n",
      "        [ 0.1903],\n",
      "        [-0.0692],\n",
      "        [ 0.2361],\n",
      "        [-0.1576],\n",
      "        [ 0.1632],\n",
      "        [-0.2281],\n",
      "        [-0.0510],\n",
      "        [-0.2344],\n",
      "        [-0.1713],\n",
      "        [-0.0218],\n",
      "        [ 0.0304],\n",
      "        [-0.1995],\n",
      "        [-0.2178],\n",
      "        [ 0.1188],\n",
      "        [ 0.1010],\n",
      "        [ 0.2034],\n",
      "        [ 0.2666],\n",
      "        [-0.2352],\n",
      "        [-0.0967],\n",
      "        [ 0.0146],\n",
      "        [ 0.2489],\n",
      "        [-0.0733],\n",
      "        [-0.1853],\n",
      "        [-0.0486],\n",
      "        [-0.1470],\n",
      "        [-0.0831],\n",
      "        [-0.2281],\n",
      "        [-0.2208],\n",
      "        [ 0.0452],\n",
      "        [ 0.1036],\n",
      "        [-0.1749],\n",
      "        [-0.1809],\n",
      "        [ 0.0268],\n",
      "        [ 0.0567],\n",
      "        [-0.2616],\n",
      "        [ 0.0534],\n",
      "        [-0.1860],\n",
      "        [ 0.1948],\n",
      "        [-0.1387],\n",
      "        [ 0.1238],\n",
      "        [-0.1067],\n",
      "        [-0.2643],\n",
      "        [-0.2038],\n",
      "        [ 0.0043],\n",
      "        [ 0.1524],\n",
      "        [-0.1190],\n",
      "        [ 0.0036],\n",
      "        [-0.2671]], requires_grad=True) size: torch.Size([80, 1])\n",
      "Parameter Parameter containing:\n",
      "tensor([0.], requires_grad=True) size: torch.Size([1])\n",
      "Parameter Parameter containing:\n",
      "tensor([[ 0.1759,  0.0109, -0.1217, -0.1337, -0.0130,  0.2029, -0.1864, -0.1232,\n",
      "         -0.0554, -0.1891,  0.1797, -0.0182,  0.1963, -0.0996, -0.1985,  0.0674,\n",
      "          0.1433, -0.1921, -0.1409, -0.2022, -0.1566,  0.1533,  0.1192,  0.1727],\n",
      "        [ 0.0032,  0.0507,  0.0728,  0.1697, -0.0601, -0.1189, -0.1754, -0.0308,\n",
      "         -0.0382,  0.1186, -0.0933,  0.1952, -0.1334, -0.0748, -0.1639, -0.1833,\n",
      "          0.1249,  0.0100,  0.1551,  0.2028,  0.0936, -0.0726, -0.0743, -0.1439],\n",
      "        [ 0.0320, -0.0269, -0.0097,  0.1717,  0.1176, -0.0203,  0.1214, -0.1436,\n",
      "         -0.1165, -0.1206,  0.0787, -0.1617, -0.1045, -0.1071,  0.0229,  0.1573,\n",
      "          0.0894, -0.0579, -0.0485, -0.1078,  0.0378,  0.1868, -0.1002,  0.1595],\n",
      "        [ 0.0073,  0.1548, -0.0124, -0.0031,  0.0746, -0.0347, -0.1612,  0.1432,\n",
      "          0.0319, -0.0616,  0.1010,  0.0172, -0.1990, -0.1368, -0.0020,  0.1506,\n",
      "          0.0458, -0.0696, -0.0082, -0.0723,  0.0644,  0.1796, -0.0930, -0.1059],\n",
      "        [ 0.1569,  0.0801,  0.0004, -0.0052, -0.1868, -0.0089, -0.0071, -0.0532,\n",
      "          0.0770, -0.0911,  0.2013, -0.1128, -0.1423,  0.0250,  0.1343,  0.1201,\n",
      "          0.0311,  0.0956, -0.1536,  0.1986, -0.0607,  0.1678, -0.0628, -0.0226],\n",
      "        [ 0.0379,  0.1761, -0.1769, -0.1311,  0.1316,  0.1569,  0.1545, -0.1205,\n",
      "         -0.0818,  0.0138,  0.0043,  0.0983, -0.1003, -0.1396, -0.1703,  0.0372,\n",
      "          0.1434,  0.1429,  0.1754, -0.0668, -0.0373, -0.0446,  0.1969,  0.0621],\n",
      "        [-0.1723, -0.1814, -0.1642,  0.0787, -0.0599,  0.1688, -0.2012, -0.0570,\n",
      "          0.1499,  0.0880, -0.1621, -0.0837,  0.0593, -0.1827,  0.0923, -0.0187,\n",
      "          0.1203, -0.0066, -0.0013, -0.0932, -0.0749, -0.1683, -0.0369,  0.0382],\n",
      "        [ 0.0259,  0.0063, -0.0872, -0.1225,  0.0870, -0.0984, -0.0068, -0.0614,\n",
      "          0.0832,  0.0453, -0.1458,  0.0507, -0.1640,  0.1757,  0.0557,  0.1094,\n",
      "         -0.0199, -0.0047, -0.1451, -0.0818,  0.1591,  0.1851,  0.1082,  0.1997],\n",
      "        [-0.0316, -0.1209,  0.1831, -0.1719,  0.1718, -0.1081, -0.0320,  0.1197,\n",
      "          0.0192,  0.1387,  0.0067,  0.0351,  0.0037, -0.1153,  0.0250,  0.0021,\n",
      "          0.1810, -0.0177,  0.1583, -0.1867, -0.1219,  0.1309, -0.1488,  0.0050],\n",
      "        [-0.1743, -0.0182,  0.0861, -0.0904, -0.0076, -0.0472, -0.0220, -0.0370,\n",
      "         -0.0096,  0.1316, -0.1896,  0.0464, -0.1720, -0.1762,  0.0325, -0.1177,\n",
      "          0.1068, -0.0521,  0.0612, -0.0888, -0.1334,  0.0851, -0.1519,  0.1694],\n",
      "        [-0.0360,  0.1717, -0.0649, -0.0492, -0.1038,  0.0160, -0.0993,  0.1879,\n",
      "         -0.0604, -0.0225, -0.1900,  0.0986,  0.1260, -0.1699, -0.0496, -0.1310,\n",
      "          0.0846,  0.1065,  0.1717, -0.1432,  0.0683,  0.0454, -0.0357,  0.0517],\n",
      "        [-0.0158,  0.1873, -0.1836,  0.1942, -0.1774,  0.1905, -0.0770, -0.1352,\n",
      "          0.0520,  0.1083, -0.0542, -0.1276, -0.0470,  0.1212, -0.0279, -0.0937,\n",
      "         -0.1250, -0.1588,  0.1090,  0.1405, -0.1637, -0.1682, -0.0842,  0.1352],\n",
      "        [ 0.0639, -0.1720, -0.0434,  0.1508,  0.1758,  0.0376,  0.1347,  0.0737,\n",
      "          0.1297, -0.1926,  0.0530,  0.0699, -0.0061, -0.0571, -0.0481,  0.0891,\n",
      "          0.0865, -0.1671, -0.0778, -0.1318, -0.0450, -0.1413, -0.1464,  0.1215],\n",
      "        [ 0.0220,  0.0752, -0.0128,  0.1277,  0.0384, -0.0672,  0.2033, -0.1646,\n",
      "         -0.1579, -0.0552,  0.0662, -0.0857, -0.0641,  0.0086,  0.1718, -0.1538,\n",
      "         -0.1976, -0.1789,  0.1047,  0.1877,  0.0463, -0.1863, -0.1493, -0.0931],\n",
      "        [ 0.1016, -0.1450,  0.1961,  0.1224, -0.0974, -0.1437, -0.0339, -0.0491,\n",
      "          0.0857, -0.1434, -0.0322,  0.0899, -0.1786, -0.0813,  0.0013, -0.0987,\n",
      "         -0.0243, -0.0804,  0.1434, -0.1176,  0.0696,  0.0317, -0.0008, -0.1641],\n",
      "        [-0.1216,  0.0139, -0.1254, -0.1453,  0.0021, -0.0115,  0.1275, -0.0755,\n",
      "         -0.1505,  0.1880,  0.1731,  0.1290, -0.1898, -0.1486, -0.1915, -0.0893,\n",
      "         -0.1444, -0.0332, -0.0520,  0.0382,  0.1806, -0.1245,  0.1529, -0.1129],\n",
      "        [-0.0746,  0.0362,  0.0706, -0.1507, -0.1736, -0.0965,  0.1619,  0.1505,\n",
      "          0.0451, -0.1612,  0.0921,  0.0327,  0.1465,  0.0869,  0.1502, -0.1653,\n",
      "         -0.0878,  0.1412,  0.0420, -0.0762, -0.0704, -0.0328,  0.0225, -0.1902],\n",
      "        [-0.0750,  0.0468,  0.1049, -0.0662, -0.1468, -0.0112,  0.0730,  0.0612,\n",
      "         -0.0084,  0.1733,  0.1044, -0.0860, -0.1540, -0.0215,  0.0911, -0.0682,\n",
      "         -0.0705, -0.1229, -0.0006, -0.1100, -0.0819, -0.1217,  0.1508, -0.0658],\n",
      "        [-0.1704, -0.2022, -0.1284, -0.0789,  0.1900, -0.0935,  0.1028, -0.1753,\n",
      "         -0.0181, -0.1946, -0.0949, -0.1010,  0.0872, -0.0614, -0.1182, -0.0223,\n",
      "         -0.0631, -0.0153,  0.0489, -0.1839,  0.1073,  0.0872,  0.0921,  0.0742],\n",
      "        [ 0.0239, -0.1553,  0.1567, -0.0823, -0.1694,  0.1686,  0.1666,  0.0575,\n",
      "          0.1173, -0.1759, -0.1907,  0.0964,  0.1550,  0.0592,  0.1978, -0.1477,\n",
      "         -0.0078,  0.0881,  0.1494,  0.0539,  0.0649,  0.0601,  0.1313, -0.0433],\n",
      "        [-0.1474, -0.0127, -0.1097,  0.1065, -0.0931,  0.0809, -0.1704,  0.0642,\n",
      "         -0.1384, -0.0369,  0.1462,  0.2022, -0.1741,  0.1853,  0.1821,  0.0973,\n",
      "         -0.0852, -0.0048,  0.1808,  0.0385, -0.1217, -0.1281,  0.1515, -0.1537],\n",
      "        [-0.0134,  0.0080,  0.0424, -0.1693,  0.1454,  0.1677,  0.1199,  0.0191,\n",
      "         -0.0686, -0.0589,  0.1044,  0.1495, -0.1252, -0.0874, -0.0506, -0.0698,\n",
      "         -0.1481,  0.1566,  0.1210, -0.1679, -0.1940, -0.1013, -0.0344,  0.1839],\n",
      "        [ 0.0863, -0.2031,  0.1497,  0.1492, -0.1925, -0.1920, -0.0731,  0.1156,\n",
      "         -0.1315, -0.1018,  0.1100,  0.0965, -0.1327,  0.1428, -0.0655, -0.0005,\n",
      "          0.1153, -0.1810, -0.0817,  0.2032,  0.0896, -0.1021,  0.1414,  0.0203],\n",
      "        [-0.0998,  0.0143, -0.1010,  0.1657, -0.0446,  0.0526, -0.0517, -0.1820,\n",
      "         -0.1299, -0.1289, -0.0811,  0.1330, -0.0785, -0.0652, -0.1229, -0.1727,\n",
      "          0.0647, -0.0908, -0.0739, -0.1306, -0.1271,  0.0980,  0.1845,  0.1285]],\n",
      "       requires_grad=True) size: torch.Size([24, 24])\n",
      "Parameter Parameter containing:\n",
      "tensor([-0.1121, -0.1065,  0.1159, -0.0767,  0.0529, -0.0948, -0.1804, -0.1346,\n",
      "         0.1183,  0.1845,  0.1434,  0.0111,  0.0650, -0.1542, -0.1833,  0.0731,\n",
      "         0.1875,  0.0157, -0.1466,  0.1830, -0.1168, -0.0780,  0.0541, -0.1215],\n",
      "       requires_grad=True) size: torch.Size([24])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7uHUoHNZoCGq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1599499509571,
     "user_tz": 300,
     "elapsed": 4321761,
     "user": {
      "displayName": "Jeehyun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GizNw5DW2QVCa5vUMiz0MiTNIYXIkGzaDCp0Es2=s64",
      "userId": "14458427846939093236"
     }
    },
    "outputId": "4990d41b-96f9-4a42-c6c0-1e0888aa55d5"
   },
   "source": [
    "# import itertools\n",
    "# optimizer = torch.optim.Adam(itertools.chain(net.parameters(), embed.parameters()), lr=0.01)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "accumulation_steps = 100\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "loss_optm = []\n",
    "ep_range = 20\n",
    "for epoch in range(ep_range):\n",
    "    # print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
    "    for sample in range(n_train):\n",
    "      x_train_one,y_train_one=get_xy(sample)\n",
    "      net.train()\n",
    "      logits = net(G, I_bus, x_train_one)\n",
    "      # loss = F.binary_cross_entropy(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
    "      # loss = F.mse_loss(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
    "      loss = F.mse_loss(logits, y_train_one) #/ accumulation_steps\n",
    "      loss.backward()\n",
    "\n",
    "      if ((sample+1)%accumulation_steps)==0:\n",
    "        optimizer.step() # update parameters of net\n",
    "        optimizer.zero_grad() # clear the psat gradient\n",
    "\n",
    "  # test for simple adaptive scheme\n",
    "    # if epoch > 10:\n",
    "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.15)\n",
    "    # if epoch > 10:\n",
    "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.04)\n",
    "    # if epoch > 20:\n",
    "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.03)\n",
    "    # if epoch > 30:\n",
    "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\n",
    "    # if epoch > 40:\n",
    "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "    # # Decay Learning Rate\n",
    "    # if epoch > 1:\n",
    "    #   scheduler.step()\n",
    "    \n",
    "    print('Epoch %d | Loss: %.4f' % (epoch + 1, loss.item()))\n",
    "    loss_optm.append(loss.item())"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.0080\n",
      "Epoch 1 | Loss: 0.0080\n",
      "Epoch 2 | Loss: 0.0080\n",
      "Epoch 3 | Loss: 0.0080\n",
      "Epoch 4 | Loss: 0.0080\n",
      "Epoch 5 | Loss: 0.0080\n",
      "Epoch 6 | Loss: 0.0080\n",
      "Epoch 7 | Loss: 0.0080\n",
      "Epoch 8 | Loss: 0.0080\n",
      "Epoch 9 | Loss: 0.0080\n",
      "Epoch 10 | Loss: 0.0080\n",
      "Epoch 11 | Loss: 0.0080\n",
      "Epoch 12 | Loss: 0.0080\n",
      "Epoch 13 | Loss: 0.0080\n",
      "Epoch 14 | Loss: 0.0080\n",
      "Epoch 15 | Loss: 0.0081\n",
      "Epoch 16 | Loss: 0.0079\n",
      "Epoch 17 | Loss: 0.0080\n",
      "Epoch 18 | Loss: 0.0080\n",
      "Epoch 19 | Loss: 0.0080\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LSw7m9Tos9MH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "ep_range1 = 5\n",
    "\n",
    "for epoch in range(ep_range1):\n",
    "    # print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
    "    for sample in range(n_train):\n",
    "      x_train_one,y_train_one=get_xy(sample)\n",
    "      net.train()\n",
    "      logits = net(G,I_bus, x_train_one)\n",
    "      # loss = F.binary_cross_entropy(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
    "      # loss = F.mse_loss(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
    "      loss = F.mse_loss(logits, y_train_one) #/ accumulation_steps\n",
    "      loss.backward()\n",
    "\n",
    "      if ((sample+1)%accumulation_steps)==0:\n",
    "        optimizer.step() # update parameters of net\n",
    "        optimizer.zero_grad() # clear the psat gradient\n",
    "\n",
    "    \n",
    "    print('Epoch %d | Loss: %.4f' % (epoch+ep_range + 1, loss.item()))\n",
    "    loss_optm.append(loss.item())"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.0080\n",
      "Epoch 21 | Loss: 0.0080\n",
      "Epoch 22 | Loss: 0.0080\n",
      "Epoch 23 | Loss: 0.0080\n",
      "Epoch 24 | Loss: 0.0080\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ0nLutzpyHX",
    "colab_type": "text"
   },
   "source": [
    "## Optimization methods:\n",
    "**We need to incorporate batch size into the optimization step size for mini batches.** \n",
    "- **Rprop:** A gradient descent algorithm that only uses the signs of gradients to compute updates. It stands for Resilient Propagation and works well in many situations because it adapts the step size dynamically for each weight independently.\n",
    "- **Learning rate scheduling:** used with optimizers\n",
    "- **lr_scheduler.StepLR:** Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/\n",
    "- **lr_scheduler.CyclicLR:** Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR). The policy cycles the learning rate between two boundaries with a constant frequency. Cyclical learning rate policy changes the learning rate after every batch. step should be called after a batch has been used for training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pfTSSX29R7jP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "plt.figure()\n",
    "plot_idx = np.arange(np.size(loss_optm))\n",
    "plt.plot(plot_idx[3:-1],loss_optm[3:-1],lw=2,label='loss level')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show(block=False)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF-gZIOko2Jd",
    "colab_type": "text"
   },
   "source": [
    "## Step 4. Validation\n",
    "**Validate the trained model using the test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uCp3fEEFGCv",
    "colab_type": "text"
   },
   "source": [
    "When a model is trained, we can use the following method to evaluate the performance of the model on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nrhVrVUb0d2t",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Generate one data pt. for testing the trained model\n",
    "def get_xy_test(index):\n",
    "    tempx=np.array([np.transpose(x_test)[index]])\n",
    "    x_train_one=torch.from_numpy(tempx).float()\n",
    "    x_train_one=x_train_one.transpose(0,1)\n",
    "\n",
    "    tempy=np.array([np.transpose(y_test)[index]])\n",
    "    y_train_one=torch.from_numpy(tempy).float()\n",
    "    y_train_one=y_train_one.transpose(0,1)\n",
    "\n",
    "    return x_train_one,y_train_one\n",
    "\n",
    "# generate torch y_train for concatenated obj\n",
    "y_test1 = torch.from_numpy(y_test)#.float()\n",
    "# expand into 3d tensor \n",
    "y_test1.unsqueeze_(-1)\n",
    "y_test1 = y_test1.expand(n_bus,n_test,1)\n",
    "y_test1 = y_test1.transpose(2,1)\n",
    "print(y_test1.shape)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1, 1200])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C5PBICs8E51B",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# model evaluation function\n",
    "def evaluate(model, g, features, labels, n, I):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      indices = torch.tensor(np.zeros((n_bus,1,n)))\n",
    "      for sample in range(n):\n",
    "        x_sample,y_sample=get_xy_test(sample)\n",
    "        logits = model(g, I, x_sample)\n",
    "        logp = logits\n",
    "        # logp = torch.sigmoid(logits)\n",
    "        # logp = F.log_softmax(logits, 1)\n",
    "        # _, indices1 = torch.max(logp, dim=1)\n",
    "        indices[:,:,sample] = logp.clone()\n",
    "\n",
    "      # correct = torch.sum(indices == labels)\n",
    "      # return correct.item() * 1.0 / len(labels)\n",
    "      return indices"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L5VvNfm_cFMD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(x_test.shape)\n",
    "print(y_test1.shape)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1200)\n",
      "torch.Size([24, 1, 1200])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YrE4bhDc64fK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# make predictions\n",
    "indices = evaluate(net, G, x_test, y_test1,n_test, I_bus)\n",
    "# test_acc = evaluate(net, G, x_test, y_test1,n_test)\n",
    "# print(\"Epoch_last {:05d} | Loss {:.4f} | Test Acc {:.4f}\".format(epoch, loss.item(), test_acc))"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "S7QRkoh8b1cm",
    "colab": {}
   },
   "source": [
    "y_test0 = y_test1.numpy().copy()\n",
    "y_pred0 = indices.numpy().copy()\n",
    "\n",
    "L_infty_err = []\n",
    "L1_err = []\n",
    "for i in range(n_test):\n",
    "  L_infty_err.append(np.max(np.abs(y_test0[:,:,i]-y_pred0[:,:,i])))\n",
    "  L1_err.append(np.sum(np.abs(y_test0[:,:,i]-y_pred0[:,:,i])))\n",
    "print('L_infty mean: ',np.mean(L_infty_err))\n",
    "print('L_1 mean: ',np.mean(L1_err))\n",
    " \n",
    "val, idx = min((val, idx) for (idx, val) in enumerate(L_infty_err))\n",
    "print(val,idx)\n",
    "# print('L_inf sample: \\n',y_test[:,:,idx])\n",
    "# print(y_pred[:,:,idx])\n",
    "val1, idx1 = min((val, idx) for (idx, val) in enumerate(L1_err))\n",
    "print(val1,idx1)\n",
    "# print('L1 sample: \\n',y_test[:,:,idx1])\n",
    "# print(y_pred[:,:,idx1])"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_infty mean:  0.4464177769009668\n",
      "L_1 mean:  1.3457193668751275\n",
      "0.1284242598215739 760\n",
      "0.4439017939160866 97\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CW9qX0nGgoS_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(load_data[0:n_bus,:].shape)\n",
    "print(y0[0:n_bus,0:n_sample].shape)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 6000)\n",
      "(24, 6000)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3pQ1v0b58NRH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Save the predictions for other training/evaluation jobs\n",
    "\n",
    "\n",
    "# import pprint\n",
    "# from os import path\n",
    "#\n",
    "# from datetime import datetime\n",
    "# from packaging import version\n",
    "\n",
    "def save_dataset(test_case, dataset):\n",
    "    file_name = test_case.split('.')[0]\n",
    "    file_path = 'drive/My Drive/gnn/numerical_results/'\n",
    "    file_dir = file_path + file_name + '.pickle'\n",
    "    outfile = open(file_dir, 'wb')\n",
    "    pickle.dump(dataset, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "def get_xy_eval(index):\n",
    "    tempx=np.array([np.transpose(load_data[0:n_bus,:])[index]])\n",
    "    x_train_one=torch.from_numpy(tempx).float()\n",
    "    x_train_one=x_train_one.transpose(0,1)\n",
    "\n",
    "    return x_train_one\n",
    "\n",
    "def model_eval(model, g, features, n, I):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      indices = torch.tensor(np.zeros((n_bus,1,n)))\n",
    "      for sample in range(n):\n",
    "        x_sample=get_xy_eval(sample)\n",
    "        logits = model(g, I, x_sample)\n",
    "        logp = logits\n",
    "        indices[:,:,sample] = logp.clone()\n",
    "\n",
    "      return indices\n",
    "\n",
    "indices = model_eval(net, G, load_data[0:n_bus,:], n_sample, I_bus)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NdH_Svt5js05",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# generation prediction by GNN model\n",
    "print(indices.shape)\n",
    "gen_pred_norm = indices.numpy().copy()\n",
    "\n",
    "y0[j,i] = np.divide(gen_exact[j,i]-gen_low_limit[j],gen_up_limit[j]-gen_low_limit[j])\n",
    "\n",
    "gen_pred = np.zeros((n_bus,n_sample))\n",
    "for i in range(n_sample):\n",
    "  for j in range(n_bus):\n",
    "    gen_pred[j,i] = indices[j,0,i] * (gen_up_limit[j]-gen_low_limit[j]) + gen_low_limit[j]\n",
    "\n",
    "dataset = {'pred': gen_pred}\n",
    "# print(dataset)\n",
    "filename = 'GNN_24bus_gen_prediction_copy_new'\n",
    "save_dataset(filename, dataset)"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1, 6000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeehyunpark/anaconda3/envs/GNN4OPF/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'drive/My Drive/gnn/numerical_results/GNN_24bus_gen_prediction_copy_new.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-91d84198b4fd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;31m# print(dataset)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'GNN_24bus_gen_prediction_copy_new'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0msave_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-24-a3117fbc61ed>\u001B[0m in \u001B[0;36msave_dataset\u001B[0;34m(test_case, dataset)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mfile_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'drive/My Drive/gnn/numerical_results/'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mfile_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mfile_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.pickle'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0moutfile\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'wb'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m     \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutfile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0moutfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'drive/My Drive/gnn/numerical_results/GNN_24bus_gen_prediction_copy_new.pickle'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lZ5hVfqjde3z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "for i in range(10):\n",
    "  print(np.sum(x_train[:,i]),np.sum(gen_pred[:,i]))\n",
    "# print(np.sum(gen_pred[:,1]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0h31WYc4LtTG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Evaluate the prediction accuracy by relative error\n",
    "acc_threshold1 = 0.05\n",
    "acc_threshold = 0.1\n",
    "\n",
    "acc_count = 0\n",
    "acc_count1 = 0\n",
    "for i in range(24):\n",
    "  if np.abs(y_test0[i,:,idx]) > 0:\n",
    "    if np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx])/np.abs(y_test0[i,:,idx]) < acc_threshold or np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx]) < acc_threshold1:\n",
    "        acc_count = acc_count+1\n",
    "    if np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1])/np.abs(y_test0[i,:,idx1]) < acc_threshold or np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1]) < acc_threshold1:\n",
    "        acc_count1 = acc_count1+1\n",
    "  else:\n",
    "    if np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx]) < acc_threshold1:\n",
    "        acc_count = acc_count+1\n",
    "    if np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1]) < acc_threshold1:\n",
    "        acc_count1 = acc_count1+1\n",
    "print('most accurate L_inf: ',acc_count,'  L_1: ',acc_count1)\n",
    "\n",
    "\n",
    "acc_test = np.zeros(y_test0.shape[0])\n",
    "for j in range(y_test0.shape[0]):\n",
    "  acc_count = 0\n",
    "  for i in range(24):\n",
    "    if np.abs(y_test0[i,:,j]) > 0:\n",
    "      if np.abs(y_test0[i,:,j]-y_pred0[i,:,j])/np.abs(y_test0[i,:,j]) < acc_threshold or np.abs(y_test0[i,:,j]-y_pred0[i,:,j]) < acc_threshold1:\n",
    "          acc_count = acc_count+1\n",
    "    else:\n",
    "      if np.abs(y_test0[i,:,j]-y_pred0[i,:,j]) < acc_threshold1:\n",
    "          acc_count = acc_count+1\n",
    "  acc_test[j] = acc_count\n",
    "print('Mean accuracy: ',np.mean(acc_test)) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SzHeOYpbIZ41",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "# for i in range(3):\n",
    "  # print('Prediction:',indices[:,:,i].transpose(0,1))\n",
    "  # print('Ture label:',y_test1[:,:,i].transpose(0,1))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu4vxBiiG7IN",
    "colab_type": "text"
   },
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kZIQUKv3G42U",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def result_reshape(data):\n",
    "    result_dim = math.ceil(math.sqrt(len(data)))\n",
    "    reshaped_data = np.zeros((result_dim, result_dim))\n",
    "\n",
    "    for i in range(result_dim):\n",
    "        for j in range(result_dim):\n",
    "            try:\n",
    "                reshaped_data[i][j] = data[result_dim * i + j]\n",
    "            except IndexError:\n",
    "                reshaped_data[i][j] = -1\n",
    "    return reshaped_data\n",
    "\n",
    "\n",
    "def test_vs_pred(y_test, y_pred,  data_idx, test_case):\n",
    "    y_test0 = y_test[:,:,data_idx]\n",
    "    y_pred0 = y_pred[:,:,data_idx]\n",
    "    y_test_reshaped = result_reshape(y_test0)\n",
    "    y_pred_reshaped = result_reshape(y_pred0)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "\n",
    "    fig.suptitle('Active Constraints Distribution: ' + test_case.split('.')[0], size=19, y=0.88)\n",
    "    axes[0].set_title('y_test', size=15, y=1.03)\n",
    "    axes[1].set_title('y_pred', size=15, y=1.03)\n",
    "    # axes[2].set_title('y_pred_binary', size=15, y=1.03)\n",
    "\n",
    "    sns.heatmap(y_test_reshaped,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                cbar_kws={'ticks': [-1, 0, 1], 'shrink': .75},\n",
    "                square=True,\n",
    "                ax=axes[0])\n",
    "\n",
    "    sns.heatmap(y_pred_reshaped,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                cbar_kws={'ticks': [-1, 0, 1], 'shrink': .75},\n",
    "                square=True,\n",
    "                ax=axes[1])\n",
    "    \n",
    "\n",
    "    fig.show()\n",
    "    # file_dir = path.join('drive/My Drive/OPF_Porject_EE394V_SPR2020-master/codes/experiments/figures/', test_case.split('.')[0] + '.png')\n",
    "    # fig.savefig(file_dir, format='png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wrfl_miqWLip",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(y_test1[:,:,1].transpose(0,1))\n",
    "print(indices[:,:,1].transpose(0,1))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LNlT68rcHGHV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# y_test1.resize_((n_bus+n_line,n_test))\n",
    "# indices_int.resize_((n_bus+n_line,n_test))\n",
    "# indices.resize_((n_bus+n_line,n_test))\n",
    "\n",
    "test_cases = [\n",
    "    'pglib_opf_case24_ieee_rts.pickle', \n",
    "]\n",
    "\n",
    "data_idx = [7,10,33,55,64,78,96]\n",
    "data_idx = np.arange(10)\n",
    "# test_vs_pred(y_test, y_pred, data_idx, test_cases[case_idx])\n",
    "for i in range(len(data_idx)):\n",
    "  test_vs_pred(y_test1, indices, data_idx[i], test_cases[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}