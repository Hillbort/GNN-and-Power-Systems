{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GNN_n2n_exact_gen_0924.ipynb","provenance":[{"file_id":"1yH55jcqo2EZ9wVWSiPdFfxyqbMTDEEpC","timestamp":1599494521560}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dJ1P8LLwoCB-"},"source":["# GNN for Optimal Generation Dispatch\n","## IEEE 24-bus RTS system \n","* System settings: 24 buses, 34 lines (concatenated from 38), 17 loads, 12 generating units on 10 buses.\n","* Data: Currently we use a dataset with ~ 6000 samples, 80% used for training and 20% for validation."]},{"cell_type":"markdown","metadata":{"id":"Fpu6oufuK7Fu","colab_type":"text"},"source":["# 0. Experiment env setting & import packages"]},{"cell_type":"code","metadata":{"id":"VPaTpHp7NApo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600986055305,"user_tz":300,"elapsed":408,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"7bec6f85-b510-4ba3-9b12-f4c4fcabf037","tags":[]},"source":["# check cuda version\n","!nvcc --version"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"zsh:1: command not found: nvcc\n"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-09T01:48:38.320098Z","start_time":"2020-09-09T01:48:38.213795Z"},"pycharm":{"name":"#%%\n"},"id":"447jyywCK7Fv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986065999,"user_tz":300,"elapsed":6156,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"tags":[]},"source":["!pip -q install gpuinfo\n","\n","from gpuinfo import GPUInfo\n","# install DGL according to the available hardware\n","if GPUInfo.check_empty() is None:\n","    print('cpu mode')\n","    !pip -q install dgl # cpu mode\n","else:\n","    print('gpu mode')\n","    !pip -q install dgl-cu101 # gpu mode"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"cpu mode\n"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-09T01:48:46.135670Z","start_time":"2020-09-09T01:48:39.457696Z"},"pycharm":{"name":"#%%\n"},"tags":[],"id":"DfsXnCWGK7Fy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1600986070766,"user_tz":300,"elapsed":1525,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"a9b4e738-b924-43d8-8b6f-c658e29ea138"},"source":["# Import necessary packages\n","import dgl # graph convolution\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import math\n","import seaborn as sns\n","import pickle\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.autograd.variable as Variable\n","from torch.utils.data import DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","from dgl.nn.pytorch.conv import GraphConv"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":"Using backend: pytorch\n"}]},{"cell_type":"markdown","metadata":{"id":"F0HSMKRKK7F1","colab_type":"text"},"source":["# 1. Dataset Preprocessing\n","## 1.1 Load the dataset"]},{"cell_type":"code","metadata":{"id":"fNyL-Q88K7F2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600986072974,"user_tz":300,"elapsed":2923,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"9f855636-3d87-4a95-eaa0-377b2ca9a9d2"},"source":["\n","# @ G-drive env\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# filename = './drive/My Drive/Colab Notebooks/ieee24_rts_6183exact_0831.txt' # active level 0.1024(line0.0124), max active line 3\n","\n","# @ Local env\n","filename = '../data/ieee24_rts_6183exact_0831.txt'  # active level 0.1024(line0.0124), max active line 3\n","\n","data = pd.read_table(filename, sep=',', header=None).to_numpy()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnvFL2JbK7F4","colab_type":"text"},"source":["## 1.2 Data preprocessing"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-09T01:48:48.231369Z","start_time":"2020-09-09T01:48:46.147790Z"},"colab_type":"code","id":"RamArMRLoCC7","colab":{},"executionInfo":{"status":"ok","timestamp":1600986077557,"user_tz":300,"elapsed":683,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# system size\n","n_bus = int(data[0, 0].copy())\n","n_line = int(data[1, 0].copy())\n","n_load = int(data[2, 0].copy())\n","n_sample = int(data[3, 0].copy())\n","\n","# line connection\n","line_bus = data[:, 1:3].copy()\n","\n","# load and corresponding line data\n","load_data0 = data[:, 3 : n_sample + 3].copy()\n","line_flow = data[:, n_sample + 3 : 2 * n_sample + 3].copy()\n","bound_idx_low = data[:, 2 * n_sample + 3 : 3 * n_sample + 3].copy()\n","bound_idx_up = data[:, 3 * n_sample + 3 : 4 * n_sample + 3].copy()\n","bound_idx0 = bound_idx_up + bound_idx_low  # may use 'np.add(a,-b)' instead\n","line_limit = data[:, 4 * n_sample + 3].copy()\n","# print(line_limit)\n","\n","# generation data\n","gen_exact = data[:, 4 * n_sample + 4 : 5 * n_sample + 4].copy()\n","gen_low_limit = data[:, 5 * n_sample + 4].copy()\n","gen_up_limit = data[:, 5 * n_sample + 5].copy()\n","\n","# normalize the generation data\n","y0 = np.zeros((n_bus, n_sample))\n","for i in range(n_sample):\n","    # y0[:,i] = np.divide(line_flow[:,i],line_limit) # w/ direction\n","    for j in range(n_bus):\n","        if gen_up_limit[j] > 0:\n","            y0[j, i] = np.divide(\n","                gen_exact[j, i] - gen_low_limit[j], gen_up_limit[j] - gen_low_limit[j]\n","            )\n","        else:\n","            y0[j, i] = 0\n","\n","# check the normalization\n","assert np.max(y0) <= 1.0 and np.min(y0) >= 0.0\n","\n","\n","# % exact generation\n","# data1(1:N,4*n+5:5*n+4) = gen_data;\n","# % generation lower bound & upper bound\n","# data1(1:N,5*n+5) = g_min;\n","# data1(1:N,5*n+6) = g_max;\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xE7m792MK7F7","colab_type":"text"},"source":["# 1.2 Check the dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yfMmqGJmru9O","tags":[],"colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1600986078328,"user_tz":300,"elapsed":324,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"0229ac6f-26d0-4c5c-e6e5-2e23497159c6"},"source":["# Use partial data for faster test\n","n_sample = 6000\n","\n","load_data = load_data0[:, :n_sample].copy()\n","bound_idx = bound_idx0[:, :n_sample].copy() * 1\n","\n","# gen_idx_low = gen_idx_low[:,:n_sample]\n","# gen_idx_up = gen_idx_up[:,:n_sample]\n","# gen_idx = gen_idx_up + gen_idx_low\n","\n","# print system info\n","print('Test case: ', filename)\n","print('Number of buses: ', n_bus)\n","print('Number of lines: ', n_line)\n","print('Number of loads: ', n_load)\n","print('Number of samples: ', n_sample)\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"Test case:  ../data/ieee24_rts_6183exact_0831.txt\nNumber of buses:  24\nNumber of lines:  34\nNumber of loads:  17\nNumber of samples:  6000\n"}]},{"cell_type":"markdown","metadata":{"id":"uXK2dRQTK7GA","colab_type":"text"},"source":["# 1.3 EDA"]},{"cell_type":"markdown","metadata":{"id":"2HYgCAkgK7GB","colab_type":"text"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"A9tAooKiK7GB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1600986079930,"user_tz":300,"elapsed":256,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"49fbd2a2-473c-4a24-ecf6-ad91436e90a6"},"source":["load_data0"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[ -30.35 ,    5.065, -256.29 , ..., -153.49 , -197.61 ,  -67.972],\n       [ -63.506, -255.7  ,   14.373, ..., -211.23 ,  -48.056, -154.33 ],\n       [-490.88 , -446.79 , -105.88 , ...,  -68.421,  -83.383, -178.69 ],\n       ...,\n       [  -0.   ,   -0.   ,   -0.   , ...,   -0.   ,   -0.   ,   -0.   ],\n       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ],\n       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ]])"},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"PSYkUxGwK7GE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1600986080388,"user_tz":300,"elapsed":396,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"5f48d9cd-97f2-4cf3-faa3-75e0e528cc09"},"source":["load_data_df = pd.DataFrame(np.transpose(load_data0))\n","load_data_df"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":"            0         1        2         3         4         5        6   \\\n0     -30.3500  -63.5060 -490.880  -73.7800  -87.3940  -31.7740 -266.970   \n1       5.0650 -255.7000 -446.790  -76.2070    5.2193  -67.6450  -62.836   \n2    -256.2900   14.3730 -105.880    9.8036 -183.3600  -78.8720 -116.520   \n3    -195.9100   -7.9061  -21.591  -35.5970 -193.3900  -13.0630 -179.410   \n4      -5.7108   -1.9999 -230.930  -35.2530 -148.0900   -4.1539 -296.200   \n...        ...       ...      ...       ...       ...       ...      ...   \n6178 -150.6200 -221.5000  -68.936 -171.6100 -177.8800   17.4640 -181.830   \n6179   10.6830 -105.9700 -293.430 -210.0500  -30.9880  -11.1690 -221.440   \n6180 -153.4900 -211.2300  -68.421 -133.0500  -82.2310 -114.5500 -117.090   \n6181 -197.6100  -48.0560  -83.383  -70.7830  -65.7330    7.6154  -18.000   \n6182  -67.9720 -154.3300 -178.690 -214.3500  -83.6070   12.0640 -359.200   \n\n           7         8         9   ...   24   25   26   27   28   29   30  \\\n0     -39.866  -82.6070 -165.3300  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n1    -237.730  -72.2040   12.6940  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n2    -357.890 -111.2900 -153.2400  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n3     -36.190   -1.9161 -243.1100  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n4     -53.374 -380.3200   -6.8886  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n...       ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n6178 -275.370 -293.8000 -112.1500  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n6179 -240.540  -77.4610  -63.1020  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n6180 -262.190  -97.6670  -82.5620  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n6181  -86.311 -254.0200 -113.9200  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n6182 -219.900  -48.8010 -243.0300  ... -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0   \n\n       31   32   33  \n0    -0.0  0.0  0.0  \n1    -0.0  0.0  0.0  \n2    -0.0  0.0  0.0  \n3    -0.0  0.0  0.0  \n4    -0.0  0.0  0.0  \n...   ...  ...  ...  \n6178 -0.0  0.0  0.0  \n6179 -0.0  0.0  0.0  \n6180 -0.0  0.0  0.0  \n6181 -0.0  0.0  0.0  \n6182 -0.0  0.0  0.0  \n\n[6183 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-30.3500</td>\n      <td>-63.5060</td>\n      <td>-490.880</td>\n      <td>-73.7800</td>\n      <td>-87.3940</td>\n      <td>-31.7740</td>\n      <td>-266.970</td>\n      <td>-39.866</td>\n      <td>-82.6070</td>\n      <td>-165.3300</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0650</td>\n      <td>-255.7000</td>\n      <td>-446.790</td>\n      <td>-76.2070</td>\n      <td>5.2193</td>\n      <td>-67.6450</td>\n      <td>-62.836</td>\n      <td>-237.730</td>\n      <td>-72.2040</td>\n      <td>12.6940</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-256.2900</td>\n      <td>14.3730</td>\n      <td>-105.880</td>\n      <td>9.8036</td>\n      <td>-183.3600</td>\n      <td>-78.8720</td>\n      <td>-116.520</td>\n      <td>-357.890</td>\n      <td>-111.2900</td>\n      <td>-153.2400</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-195.9100</td>\n      <td>-7.9061</td>\n      <td>-21.591</td>\n      <td>-35.5970</td>\n      <td>-193.3900</td>\n      <td>-13.0630</td>\n      <td>-179.410</td>\n      <td>-36.190</td>\n      <td>-1.9161</td>\n      <td>-243.1100</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-5.7108</td>\n      <td>-1.9999</td>\n      <td>-230.930</td>\n      <td>-35.2530</td>\n      <td>-148.0900</td>\n      <td>-4.1539</td>\n      <td>-296.200</td>\n      <td>-53.374</td>\n      <td>-380.3200</td>\n      <td>-6.8886</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6178</th>\n      <td>-150.6200</td>\n      <td>-221.5000</td>\n      <td>-68.936</td>\n      <td>-171.6100</td>\n      <td>-177.8800</td>\n      <td>17.4640</td>\n      <td>-181.830</td>\n      <td>-275.370</td>\n      <td>-293.8000</td>\n      <td>-112.1500</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6179</th>\n      <td>10.6830</td>\n      <td>-105.9700</td>\n      <td>-293.430</td>\n      <td>-210.0500</td>\n      <td>-30.9880</td>\n      <td>-11.1690</td>\n      <td>-221.440</td>\n      <td>-240.540</td>\n      <td>-77.4610</td>\n      <td>-63.1020</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6180</th>\n      <td>-153.4900</td>\n      <td>-211.2300</td>\n      <td>-68.421</td>\n      <td>-133.0500</td>\n      <td>-82.2310</td>\n      <td>-114.5500</td>\n      <td>-117.090</td>\n      <td>-262.190</td>\n      <td>-97.6670</td>\n      <td>-82.5620</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6181</th>\n      <td>-197.6100</td>\n      <td>-48.0560</td>\n      <td>-83.383</td>\n      <td>-70.7830</td>\n      <td>-65.7330</td>\n      <td>7.6154</td>\n      <td>-18.000</td>\n      <td>-86.311</td>\n      <td>-254.0200</td>\n      <td>-113.9200</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6182</th>\n      <td>-67.9720</td>\n      <td>-154.3300</td>\n      <td>-178.690</td>\n      <td>-214.3500</td>\n      <td>-83.6070</td>\n      <td>12.0640</td>\n      <td>-359.200</td>\n      <td>-219.900</td>\n      <td>-48.8010</td>\n      <td>-243.0300</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6183 rows × 34 columns</p>\n</div>"},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"edsjlYcJK7GG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986080613,"user_tz":300,"elapsed":286,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"5T1ig-4gK7GI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986080913,"user_tz":300,"elapsed":206,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"k3lGNqfWK7GK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986081365,"user_tz":300,"elapsed":258,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fnCkKSNfK7GM","colab_type":"text"},"source":["## Gen Data"]},{"cell_type":"code","metadata":{"id":"pVyxnl0eK7GM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600986081906,"user_tz":300,"elapsed":294,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"00a85794-aa6d-4bc0-8dc8-0d4f1f6e8b49"},"source":["y0[0]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([0.9382716 , 0.75270062, 0.99868827, ..., 0.9382716 , 0.        ,\n       0.95671296])"},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"926O31K-K7GO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1600986082201,"user_tz":300,"elapsed":361,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"53b74f2e-2343-4938-93c5-5f44c086c84f"},"source":["gen_data_df = pd.DataFrame(np.transpose(y0))\n","gen_data_df"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":"            0         1    2    3    4    5         6    7    8    9   ...  \\\n0     0.938272  0.938272  0.0  0.0  0.0  0.0  0.452311  0.0  0.0  0.0  ...   \n1     0.752701  0.752701  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...   \n2     0.998688  1.000000  0.0  0.0  0.0  0.0  0.962311  0.0  0.0  0.0  ...   \n3     0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...   \n4     0.938272  0.938272  0.0  0.0  0.0  0.0  0.559822  0.0  0.0  0.0  ...   \n...        ...       ...  ...  ...  ...  ...       ...  ...  ...  ...  ...   \n6178  0.938272  0.938272  0.0  0.0  0.0  0.0  0.741956  0.0  0.0  0.0  ...   \n6179  0.938272  0.938272  0.0  0.0  0.0  0.0  1.000000  0.0  0.0  0.0  ...   \n6180  0.938272  0.938272  0.0  0.0  0.0  0.0  0.795644  0.0  0.0  0.0  ...   \n6181  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...   \n6182  0.956713  1.000000  0.0  0.0  0.0  0.0  1.000000  0.0  0.0  0.0  ...   \n\n            14        15   16        17   18   19   20   21        22   23  \n0     0.677202  1.000000  0.0  1.000000  0.0  0.0  1.0  1.0  1.000000  0.0  \n1     0.677202  1.000000  0.0  1.000000  0.0  0.0  1.0  1.0  1.000000  0.0  \n2     0.000000  0.000000  0.0  0.228033  0.0  0.0  1.0  1.0  1.000000  0.0  \n3     0.646873  0.955214  0.0  1.000000  0.0  0.0  1.0  1.0  0.884492  0.0  \n4     0.677202  1.000000  0.0  1.000000  0.0  0.0  1.0  1.0  1.000000  0.0  \n...        ...       ...  ...       ...  ...  ...  ...  ...       ...  ...  \n6178  0.677202  1.000000  0.0  1.000000  0.0  0.0  1.0  1.0  1.000000  0.0  \n6179  0.912643  1.000000  0.0  1.000000  0.0  0.0  1.0  1.0  1.000000  0.0  \n6180  0.677202  0.542006  0.0  1.000000  0.0  0.0  1.0  1.0  1.000000  0.0  \n6181  0.577606  0.852929  0.0  1.000000  0.0  0.0  1.0  1.0  0.791760  0.0  \n6182  0.959247  1.000000  0.0  0.828733  0.0  0.0  1.0  1.0  1.000000  0.0  \n\n[6183 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.938272</td>\n      <td>0.938272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.452311</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.677202</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.752701</td>\n      <td>0.752701</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.677202</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998688</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.962311</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.228033</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.646873</td>\n      <td>0.955214</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.884492</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.938272</td>\n      <td>0.938272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.559822</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.677202</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6178</th>\n      <td>0.938272</td>\n      <td>0.938272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.741956</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.677202</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6179</th>\n      <td>0.938272</td>\n      <td>0.938272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.912643</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6180</th>\n      <td>0.938272</td>\n      <td>0.938272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.795644</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.677202</td>\n      <td>0.542006</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6181</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.577606</td>\n      <td>0.852929</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.791760</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6182</th>\n      <td>0.956713</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.959247</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.828733</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6183 rows × 24 columns</p>\n</div>"},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"UbO7ViLSK7GR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986082414,"user_tz":300,"elapsed":335,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtXRxCVEK7GZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986083711,"user_tz":300,"elapsed":234,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"-WbUaxBgK7Gb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986083928,"user_tz":300,"elapsed":284,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eOjKm_RBoCCA"},"source":["# 2. Creating a graph in DGL\n","* Generate and visualize the DGL graph"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NxaGvjWGoCEH","colab":{},"executionInfo":{"status":"ok","timestamp":1600986084636,"user_tz":300,"elapsed":586,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["def build_system_graph(src, dst):\n","    # Edges are directional in DGL; Make them bi-directional.\n","    # Matlab counts from 1 and python from 0\n","    u = np.concatenate([src, dst]) - 1\n","    v = np.concatenate([dst, src]) - 1\n","    # Construct a DGLGraph\n","    return dgl.DGLGraph((u, v))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H3zws2wBoCEd","tags":[],"colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600986084763,"user_tz":300,"elapsed":183,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"f36a064c-eb9a-4124-92ba-cc9f05b9b87c"},"source":["line_src = line_bus[:,0].copy().astype(int)\n","line_dst = line_bus[:,1].copy().astype(int)\n","\n","G = build_system_graph(line_src,line_dst)\n","\n","# check G's properties\n","print(\"- variable type: {}\".format(type(G)))\n","print(\"- device: {}\".format(G.device))\n","print('- node num: {}'.format(G.number_of_nodes()))\n","print('- edge num: {}'.format(G.number_of_edges()))\n","\n","# import networkx as nx\n","# Since the actual graph is undirected, we convert it for visualization\n","# purpose.\n","# nx_G = G.to_networkx().to_undirected()\n","# # Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n","# pos = nx.kamada_kawai_layout(nx_G)\n","# nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"- variable type: &lt;class &#39;dgl.heterograph.DGLHeteroGraph&#39;&gt;\n- device: cpu\n- node num: 24\n- edge num: 68\n"}]},{"cell_type":"code","metadata":{"id":"zIzvpz8vK7Gh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986085665,"user_tz":300,"elapsed":299,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HLmJ64bCoCFJ"},"source":["# 3. Assign features to nodes, edges\n","\n","e.g.: Graph neural networks associate features with nodes and edges for training.\n","\n","* In our case, inputs on nodes, features on egdes\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7xqplmGwoCFe","colab":{},"executionInfo":{"status":"ok","timestamp":1600986088348,"user_tz":300,"elapsed":354,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# # In DGL, you can add features for all nodes at once, using a feature tensor that\n","# # batches node features along the first dimension. The code below adds the learnable\n","# # embeddings for all nodes:\n","\n","# embed_feature = 10\n","# embed = nn.Embedding(G.number_of_edges(), embed_feature)  \n","# # 68 edges with embedding dim equal to 10 for edge classification\n","# G.edata['feat'] = embed.weight"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eHOzg-9PoCF3"},"source":["# 4. Define a Graph Convolutional Network (GCN) and Train the model\n","\n","To perform node classification, use the Graph Convolutional Network\n","(GCN) developed by `Kipf and Welling <https://arxiv.org/abs/1609.02907>`_. Here\n","is the simplest definition of a GCN framework. We recommend that you \n","read the original paper for more details.\n","\n","- At layer $l$, each node $v_i^l$ carries a feature vector $h_i^l$.\n","- Each layer of the GCN tries to aggregate the features from $u_i^{l}$ where\n","  $u_i$'s are neighborhood nodes to $v$ into the next layer representation at\n","  $v_i^{l+1}$. This is followed by an affine transformation with some\n","  non-linearity.\n","\n"," **In this project we use weighted graph convolution and weights are \n","learned during the trainning process.**\n","\n","The above definition of GCN fits into a **message-passing** paradigm: Each\n","node will update its own feature with information sent from neighboring\n","nodes. A graphical demonstration is displayed below.\n","\n","\n","In DGL, we provide implementations of popular Graph Neural Network layers under\n","the `dgl.<backend>.nn` subpackage. The :class:`~dgl.nn.pytorch.GraphConv` module\n","implements one Graph Convolutional layer."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eBIgnqqtoCGB"},"source":["**In our case, we want to perform edge classification based on feature inputs from nodes.**\n","* Thus we need to redesign the GNN to map the features from node to deges\n","* Define a deeper GCN model that contains two GCN layers:\n","\n","We first try convolutions on the nodes first then map to edges then try mapping to edges first then do convolutions on edges"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-23T23:46:13.428662Z","start_time":"2020-09-23T23:46:13.261516Z"},"colab_type":"code","id":"J2fkZxWsoCGP","colab":{},"executionInfo":{"status":"ok","timestamp":1600986092572,"user_tz":300,"elapsed":260,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# One layer Graph convolution from nodes to edges\n","class Graph_convolution_v2e(nn.Module):\n","    def __init__(self, in_features, out_features, W, bias=True):\n","        super(Graph_convolution_v2e, self).__init__()\n","        #         self.Weight=nn.Parameter(torch.Tensor(W))\n","        #         self.Weight=nn.Parameter(torch.from_numpy(W))\n","        self.register_buffer(\"w\", torch.from_numpy(W).float())\n","        #         for temp in self.Weight:\n","        #             temp.requires_grad=False\n","        #         self.Weight = self.Weight.detach()\n","        self.scale = nn.Parameter(torch.Tensor(out_features, 1))\n","        self.bias = nn.Parameter(torch.Tensor(out_features, 1))\n","\n","    def forward(self, input):\n","        # print(input.shape)\n","        # print(self.scale.shape)\n","        h = torch.matmul(Variable(self.w), input)\n","        return torch.mul(h, self.scale) + self.bias\n","\n","\n","# Need to change that to our case: 2 networks, one node clustering (or double it as in the reference),\n","# one node to edge.\n","\n","# Set dummy bus signals as zero\n","# Q. why ???\n","I_bus = np.identity(n_bus)\n","idx = [2, 3, 4, 5, 7, 8, 9, 10, 11, 16, 18, 19, 23]\n","for i in range(len(idx)):\n","    I_bus[idx, idx] = 0\n","I_bus = torch.from_numpy(I_bus).float()\n","\n","# GNN using DGL v2v graph convolution and our own v2e graph convolution\n","class GCN(nn.Module):\n","    def __init__(self, in_feats, hidden_size, num_nodes):\n","        super(GCN, self).__init__()\n","        self.conv1 = GraphConv(\n","            in_feats,\n","            hidden_size[0],\n","            norm=\"both\",\n","            weight=True,\n","            bias=True,\n","            activation=None,\n","        )\n","        # norm='both', weight=True, bias=True, activation=None\n","        self.conv2 = GraphConv(\n","            hidden_size[0],\n","            hidden_size[1],\n","            norm=\"both\",\n","            weight=True,\n","            bias=True,\n","            activation=None,\n","        )\n","        self.conv3 = GraphConv(\n","            hidden_size[1],\n","            hidden_size[2],\n","            norm=\"both\",\n","            weight=True,\n","            bias=True,\n","            activation=None,\n","        )\n","        self.conv4 = GraphConv(\n","            hidden_size[2],\n","            hidden_size[3],\n","            norm=\"both\",\n","            weight=True,\n","            bias=True,\n","            activation=None,\n","        )\n","        self.conv5 = GraphConv(\n","            hidden_size[3],\n","            hidden_size[4],\n","            norm=\"both\",\n","            weight=True,\n","            bias=True,\n","            activation=None,\n","        )\n","        self.conv6 = GraphConv(\n","            hidden_size[4],\n","            hidden_size[5],\n","            norm=\"both\",\n","            weight=True,\n","            bias=True,\n","            activation=None,\n","        )\n","        # self.conv7 = GraphConv(hidden_size[5], hidden_size[6],norm='both', weight=True, bias=True, activation=None)\n","        # self.conv8 = GraphConv(hidden_size[6], hidden_size[7],norm='both', weight=True, bias=True, activation=None)\n","        # self.conv9 = GraphConv(hidden_size[7], hidden_size[8],norm='both', weight=True, bias=True, activation=None)\n","        # self.conv3 = Graph_convolution_v2e(hidden_size[1], num_edges, W)\n","        # self.W = W\n","\n","        self.lin_output = nn.Linear(num_nodes, num_nodes)\n","\n","    def forward(self, g, I, inputs):  # I ???\n","        # g is the graph stored in DGL\n","        # print(g)\n","        # nx_G = g.to_networkx().to_undirected()\n","        # pos = nx.kamada_kawai_layout(nx_G)\n","        # nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])\n","        # print('inputs data type:', inputs.data.type())\n","        # print(inputs.shape)\n","        h = self.conv1(g, inputs)\n","        # h = torch.sigmoid(h)\n","        # print(h.shape)\n","        h = self.conv2(g, h)\n","        # print(h.shape)\n","        h = torch.sigmoid(h)\n","        # print(h.shape)\n","        h = self.conv3(g, h)\n","        # h = torch.sigmoid(h)\n","        h = self.conv4(g, h)\n","        h = torch.sigmoid(h)\n","        h = self.conv5(g, h)\n","        # h = torch.sigmoid(h)\n","        h = self.conv6(g, h)\n","        h = torch.sigmoid(h)\n","        # h = self.conv7(g, h)\n","        # # h = torch.sigmoid(h)\n","        # h = self.conv8(g, h)\n","        # h = torch.sigmoid(h)\n","        # h = self.conv9(g, h)\n","        # h = torch.sigmoid(h)\n","        # h = self.conv3(h)\n","        # h = torch.matmul(I,h)\n","        h = self.lin_output(h.transpose(0, 1)).transpose(0, 1)\n","        # h = torch.matmul(I,h)\n","        return h\n","\n","\n","# net = GCN_self(n_bus, [10,10], n_line, W, W1)\n","# net = GCN(n_bus, [10,10,10,10,10,10,10,1], n_line, W1)\n","w_params = [40, 80, 80, 80, 80, 1]\n","net = GCN(1, w_params, n_bus)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"ABRt7ytHK7Gp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600986104208,"user_tz":300,"elapsed":446,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"c3c29e5d-3dfb-40c5-f41e-dc32d2d20011"},"source":["# GNN model information\n","print('Network info:{}\\n'.format(net)) # in = 1 ??? \n","\n","for weight_param in net.parameters():\n","    print('> WeightParam size: {}\\n> {}\\n'.format(weight_param.shape, weight_param))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"Network info:GCN(\n  (conv1): GraphConv(in=1, out=40, normalization=both, activation=None)\n  (conv2): GraphConv(in=40, out=80, normalization=both, activation=None)\n  (conv3): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv4): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv5): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv6): GraphConv(in=80, out=1, normalization=both, activation=None)\n  (lin_output): Linear(in_features=24, out_features=24, bias=True)\n)\n\n&gt; WeightParam size: torch.Size([1, 40])\n&gt; Parameter containing:\ntensor([[ 0.1500, -0.0028,  0.2221,  0.3634, -0.3642, -0.2396, -0.1820, -0.1030,\n          0.0096, -0.0272,  0.3685,  0.2092,  0.1977,  0.2740,  0.2341,  0.1265,\n         -0.2172,  0.1501, -0.1699,  0.1448,  0.0304,  0.1165,  0.2984, -0.0770,\n          0.1101, -0.0943, -0.1832,  0.3768,  0.3591, -0.2407, -0.2889, -0.1675,\n         -0.2077, -0.1535, -0.1424, -0.1473,  0.3153,  0.2938,  0.2477,  0.2312]],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([40])\n&gt; Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([40, 80])\n&gt; Parameter containing:\ntensor([[ 0.0527,  0.2221, -0.0367,  ..., -0.2162, -0.0799, -0.1523],\n        [-0.0654, -0.1620, -0.1878,  ...,  0.1001, -0.0505,  0.1424],\n        [-0.1128, -0.0495, -0.0525,  ..., -0.2005, -0.0943,  0.0852],\n        ...,\n        [-0.2205,  0.0040, -0.0241,  ..., -0.1734,  0.1521,  0.1663],\n        [ 0.1110, -0.1224,  0.0110,  ..., -0.1166, -0.0909, -0.1707],\n        [ 0.0292, -0.2126, -0.2153,  ..., -0.2230,  0.2235, -0.0677]],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80])\n&gt; Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80, 80])\n&gt; Parameter containing:\ntensor([[-0.0579,  0.0465, -0.1079,  ...,  0.1897, -0.0507, -0.1604],\n        [-0.0207, -0.1030,  0.0954,  ...,  0.1144,  0.0588,  0.0621],\n        [-0.1012,  0.0228,  0.0053,  ..., -0.0401,  0.1282, -0.1555],\n        ...,\n        [ 0.1009, -0.0339, -0.1671,  ..., -0.0178,  0.1926,  0.0986],\n        [-0.0435,  0.0324, -0.0135,  ...,  0.1597, -0.0277,  0.0394],\n        [ 0.0253, -0.1227, -0.1360,  ..., -0.0945,  0.0432, -0.1114]],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80])\n&gt; Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80, 80])\n&gt; Parameter containing:\ntensor([[-0.0078,  0.0741, -0.1442,  ...,  0.0445,  0.1607,  0.0325],\n        [-0.1660, -0.0645,  0.1401,  ..., -0.0345, -0.1683, -0.1670],\n        [-0.0031, -0.0195,  0.1343,  ..., -0.0818, -0.0735,  0.0199],\n        ...,\n        [-0.1771, -0.1519,  0.0394,  ..., -0.1791,  0.0234, -0.0960],\n        [-0.0561, -0.1229, -0.0904,  ..., -0.1769, -0.1816, -0.1773],\n        [-0.0905,  0.1729, -0.0116,  ..., -0.0808, -0.0734,  0.0940]],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80])\n&gt; Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80, 80])\n&gt; Parameter containing:\ntensor([[-0.1186,  0.1812,  0.0883,  ..., -0.1059, -0.0664, -0.1788],\n        [-0.1461, -0.1365,  0.1214,  ...,  0.1229, -0.0234, -0.0908],\n        [-0.1381,  0.0687,  0.0580,  ...,  0.1163,  0.1217,  0.0247],\n        ...,\n        [-0.0175,  0.1752, -0.1070,  ..., -0.1741,  0.0967, -0.0326],\n        [ 0.1284, -0.1592,  0.0214,  ..., -0.0418, -0.0914, -0.0879],\n        [ 0.0386, -0.0232,  0.0815,  ..., -0.0235,  0.1769, -0.1744]],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80])\n&gt; Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n\n&gt; WeightParam size: torch.Size([80, 1])\n&gt; Parameter containing:\ntensor([[-0.2263],\n        [-0.2593],\n        [-0.1155],\n        [ 0.2662],\n        [ 0.2381],\n        [-0.0858],\n        [-0.1675],\n        [ 0.0721],\n        [ 0.1576],\n        [-0.2080],\n        [ 0.1216],\n        [-0.2277],\n        [-0.1754],\n        [ 0.1943],\n        [ 0.2663],\n        [-0.2638],\n        [-0.1182],\n        [-0.0710],\n        [ 0.0946],\n        [ 0.2236],\n        [ 0.1976],\n        [-0.2429],\n        [ 0.2685],\n        [ 0.0524],\n        [ 0.1421],\n        [-0.2160],\n        [-0.0787],\n        [-0.2009],\n        [ 0.0084],\n        [-0.1819],\n        [-0.2276],\n        [ 0.1030],\n        [ 0.1999],\n        [-0.0539],\n        [ 0.1629],\n        [-0.1100],\n        [ 0.1334],\n        [-0.0652],\n        [ 0.1128],\n        [-0.1970],\n        [-0.2574],\n        [-0.1811],\n        [-0.0403],\n        [ 0.0922],\n        [ 0.0829],\n        [-0.0336],\n        [-0.2017],\n        [-0.1031],\n        [ 0.0665],\n        [-0.1681],\n        [-0.1928],\n        [ 0.1954],\n        [ 0.2527],\n        [ 0.1280],\n        [-0.2607],\n        [-0.0216],\n        [-0.1457],\n        [ 0.2389],\n        [ 0.0132],\n        [-0.0026],\n        [-0.0484],\n        [-0.0652],\n        [-0.0517],\n        [-0.1746],\n        [-0.0150],\n        [ 0.2472],\n        [-0.1406],\n        [ 0.2259],\n        [-0.1164],\n        [-0.2262],\n        [ 0.1360],\n        [-0.1553],\n        [ 0.2301],\n        [ 0.0008],\n        [ 0.0022],\n        [-0.0210],\n        [-0.2450],\n        [ 0.1644],\n        [ 0.0995],\n        [ 0.1938]], requires_grad=True)\n\n&gt; WeightParam size: torch.Size([1])\n&gt; Parameter containing:\ntensor([0.], requires_grad=True)\n\n&gt; WeightParam size: torch.Size([24, 24])\n&gt; Parameter containing:\ntensor([[-9.9091e-02,  1.9241e-01,  3.9627e-02, -1.7772e-01, -4.5547e-03,\n         -4.5616e-02, -2.1765e-03, -1.7267e-04, -1.0263e-01,  4.4651e-02,\n          1.6837e-01, -1.3134e-02, -1.9830e-01,  6.3808e-02, -3.8595e-02,\n         -1.4696e-01, -2.7846e-02, -5.9405e-02,  1.6071e-01, -1.7297e-01,\n         -1.0148e-01, -1.6530e-01, -9.7568e-03, -1.0835e-02],\n        [-2.9207e-03,  1.5357e-01,  1.3283e-01, -1.8527e-01,  7.4467e-02,\n          2.8092e-03, -4.1628e-02, -5.8661e-02, -8.4632e-02, -6.9377e-03,\n         -1.3489e-01,  3.2018e-02, -1.1281e-01,  1.3533e-02, -9.2164e-02,\n         -9.4280e-02, -5.0183e-02,  1.2196e-01,  3.3521e-02, -5.4957e-02,\n          3.1773e-03,  7.2971e-02, -1.1703e-01,  1.7057e-01],\n        [-7.1676e-02,  4.1464e-02, -8.7563e-02,  4.8521e-02,  4.5143e-02,\n         -1.0123e-01,  6.5506e-02,  8.5027e-02,  1.2287e-01,  1.5257e-01,\n          1.2600e-01,  1.3314e-01, -1.3307e-01, -3.4966e-02, -1.2344e-01,\n          1.1183e-01, -1.8373e-01, -5.6797e-02,  7.5434e-02, -2.8590e-02,\n         -1.0530e-01,  1.4330e-01, -1.8448e-01,  1.2112e-02],\n        [-1.4499e-01,  8.6133e-02,  1.2274e-01, -1.8323e-01,  5.0928e-02,\n         -1.8872e-01,  8.4995e-02, -4.3267e-02,  1.3837e-01, -9.3713e-02,\n          1.8102e-01,  1.3262e-01, -8.5395e-03,  5.1086e-02, -1.6813e-01,\n          1.4707e-01,  1.9021e-01,  8.0270e-02, -2.0205e-01,  2.0082e-01,\n          1.2550e-01, -4.1681e-02, -1.0705e-01,  7.1240e-02],\n        [ 1.0057e-01,  1.0810e-01, -2.0093e-01, -2.0722e-02, -1.2598e-01,\n         -9.3183e-02, -1.9118e-01,  1.7584e-01,  6.0977e-02,  5.1419e-02,\n         -1.0446e-01, -3.6126e-02,  9.1452e-02, -1.9880e-01, -1.3236e-02,\n          1.9043e-01,  2.3123e-03,  1.6606e-01,  1.2134e-01,  6.4129e-02,\n         -1.5632e-01, -1.8163e-01,  2.6866e-02,  2.0303e-01],\n        [ 2.6433e-02,  1.1104e-01,  6.4937e-02, -4.2579e-02,  1.1955e-01,\n         -1.3018e-01, -6.5623e-02,  6.6601e-02,  1.4105e-01,  1.4608e-01,\n         -1.2596e-01,  1.6348e-01,  1.4564e-01, -6.8416e-02,  1.3260e-01,\n          1.5243e-01, -4.4950e-02, -1.6419e-01, -2.9428e-03, -1.6636e-01,\n          1.1549e-02,  3.9041e-02,  2.0347e-01,  1.3049e-01],\n        [-1.6546e-01,  1.3311e-01, -6.2302e-02, -1.0659e-01,  1.7494e-01,\n          1.1484e-01, -1.0449e-01,  3.3896e-02,  8.3857e-02, -1.4380e-01,\n          2.0081e-02,  9.3259e-02, -1.8016e-01,  1.1233e-01, -1.2822e-01,\n         -1.1031e-01,  5.0821e-02, -1.8137e-01, -1.9830e-01, -2.0139e-01,\n         -4.9756e-02, -1.9179e-01,  8.9012e-02, -1.8732e-01],\n        [ 1.2754e-01,  4.4902e-02, -1.3960e-01, -1.8005e-01, -1.2448e-01,\n         -1.2545e-01, -2.1014e-03,  1.5933e-02, -6.1204e-02, -9.6246e-02,\n          1.1304e-01,  1.2767e-01, -1.5458e-01,  1.6933e-01, -1.1169e-01,\n         -1.4039e-01,  1.1604e-01,  1.1883e-01, -1.9035e-01,  3.9696e-02,\n          1.5653e-01, -1.0155e-01, -1.1199e-01, -1.5999e-01],\n        [-9.3522e-02, -6.3493e-02, -6.5444e-02, -5.3869e-02,  1.1798e-01,\n          1.8485e-02, -1.4066e-01,  6.7194e-02, -1.6643e-01, -3.4843e-02,\n         -1.3344e-01,  1.7301e-01,  1.2267e-01,  5.7531e-03, -6.4572e-02,\n          5.7408e-02,  1.5484e-02,  1.8397e-01, -1.8409e-01, -1.0507e-01,\n         -1.1441e-02, -1.7452e-01,  4.7122e-02, -9.1241e-02],\n        [-1.9453e-01, -1.8301e-01,  2.0128e-02, -1.6593e-01,  1.1521e-01,\n          1.5030e-01, -6.4439e-02, -1.8732e-01,  1.4304e-01, -4.0218e-02,\n         -1.3202e-02,  8.5232e-02, -1.8849e-01,  1.5166e-01,  1.1068e-01,\n         -1.2359e-01,  1.6307e-02,  2.6187e-02, -1.0132e-01, -1.9426e-02,\n          1.4143e-01, -4.6562e-02, -3.8655e-02,  8.5777e-02],\n        [ 1.0664e-01,  4.3288e-02,  8.3641e-03, -1.4079e-01,  7.2752e-02,\n          1.7567e-01,  1.8765e-01, -2.6450e-02,  1.6216e-01,  1.8196e-01,\n         -1.1407e-01, -1.6451e-01, -4.3602e-02,  7.7182e-02, -1.1937e-01,\n         -6.9235e-02, -1.1406e-01,  9.6305e-02,  8.2252e-03,  9.8640e-02,\n          2.2887e-02, -4.7635e-02,  1.4564e-01, -1.6914e-02],\n        [-8.6334e-02,  1.0256e-01, -1.6544e-01,  1.2910e-01,  1.5851e-01,\n         -6.8715e-02,  1.2236e-03,  1.6291e-01, -1.6602e-01,  7.7215e-02,\n         -9.1435e-02,  2.0223e-02,  1.1537e-01,  1.6991e-01,  1.9559e-01,\n         -1.7915e-01,  1.2583e-01,  4.2116e-02, -2.4901e-02, -1.1957e-01,\n          1.4615e-01, -2.3369e-02,  7.3802e-03,  4.2536e-02],\n        [-9.4146e-02,  2.0291e-01, -8.7951e-03,  1.6725e-01, -1.5669e-01,\n         -4.3195e-02,  2.2194e-02,  1.2941e-01, -1.9806e-01,  1.1939e-01,\n         -1.7201e-01, -1.0476e-01, -1.7895e-01,  1.9310e-02,  1.1985e-01,\n         -6.9914e-02,  1.7375e-01,  1.6533e-01, -1.9282e-01, -7.8716e-02,\n          1.8758e-01,  6.0029e-02, -1.2499e-01, -2.6041e-02],\n        [ 1.1169e-01, -9.4545e-02,  4.4451e-02,  1.5468e-01, -1.9775e-02,\n          1.3219e-01,  1.5915e-01, -9.3988e-03,  1.6788e-01, -1.8801e-01,\n         -1.9104e-02, -1.5255e-01, -9.1852e-02, -1.9615e-01,  8.5753e-02,\n          1.3007e-01, -9.0381e-03, -4.4876e-02, -1.9068e-01,  1.5631e-01,\n         -1.8595e-01, -1.6396e-01, -1.5952e-01, -1.9252e-01],\n        [ 9.5936e-02, -1.2149e-01,  1.3843e-02,  1.4274e-01, -1.0268e-01,\n          1.7303e-01, -1.5292e-01, -2.0202e-01,  1.6971e-01,  1.2262e-01,\n         -1.4310e-01, -1.0908e-01,  1.4844e-01,  8.8305e-02,  4.2024e-02,\n          1.8679e-01, -1.7802e-01, -1.5169e-01, -8.0755e-02,  1.8042e-01,\n          1.0157e-01, -7.6181e-02, -1.6935e-01,  1.2661e-01],\n        [ 1.4829e-01,  1.3191e-01,  1.1191e-01,  6.2540e-02,  4.6960e-02,\n          1.2566e-01,  6.8462e-02,  7.5866e-02,  2.0279e-01,  1.7934e-01,\n          1.3889e-01, -2.3843e-02,  1.1655e-01,  8.0942e-02,  1.1289e-01,\n         -1.6430e-01,  1.2133e-01,  4.2634e-02,  1.6355e-01,  3.3611e-02,\n          4.4504e-02,  1.1490e-02, -1.5004e-01,  7.1899e-02],\n        [ 1.5679e-01,  6.9022e-02, -9.1197e-02,  1.6068e-01,  1.6965e-01,\n         -1.7115e-01, -3.9176e-02, -1.5367e-01, -1.7993e-01, -1.6129e-01,\n         -1.3326e-01,  2.8609e-04,  1.4073e-02, -9.4523e-02, -1.7119e-01,\n          3.8933e-02,  1.1547e-01,  2.4800e-02,  1.9529e-01, -1.5387e-01,\n         -1.1032e-01,  5.6495e-02, -5.6145e-02, -2.6918e-02],\n        [ 2.0204e-01, -1.6737e-01, -1.9320e-01,  1.3240e-01,  2.0048e-01,\n          3.0965e-02, -1.6196e-01, -7.5119e-02,  1.1440e-01, -5.7778e-02,\n         -1.5849e-01, -1.5375e-01,  2.5280e-02,  9.3222e-02,  1.4228e-01,\n          1.3194e-01,  2.4912e-02, -1.7007e-01,  1.0317e-01, -1.8660e-01,\n         -1.1438e-01,  2.0918e-02, -6.3879e-02, -1.3258e-01],\n        [ 1.6685e-01,  6.6693e-02, -1.1262e-01, -9.3849e-02,  3.2393e-02,\n          9.9779e-02, -1.6116e-01,  1.8703e-01, -1.6717e-01, -1.2914e-01,\n          8.3294e-02, -1.3191e-01,  1.9136e-01,  4.9036e-02,  9.7821e-02,\n          1.4432e-01,  1.8191e-01,  1.9561e-01, -1.3524e-02,  1.8173e-01,\n          1.0636e-01, -7.6105e-02, -6.9698e-02,  9.9940e-03],\n        [-1.2654e-01, -1.2290e-02, -1.5468e-01, -5.8973e-02, -3.0500e-02,\n         -1.5631e-01, -2.7050e-02, -9.5899e-02, -1.2215e-01, -4.7011e-02,\n         -1.6681e-01,  8.0146e-02,  1.2059e-01, -4.4408e-03, -1.7318e-01,\n          5.6141e-02, -2.2992e-02,  8.9489e-03,  1.1780e-01, -2.3488e-03,\n          1.6282e-01,  1.6616e-02, -7.9263e-02, -7.0543e-02],\n        [-1.6628e-01, -6.7214e-02, -6.8925e-04, -3.7760e-03,  7.7747e-02,\n          6.8412e-02, -7.4511e-02,  2.0351e-01, -5.2827e-02, -1.9762e-01,\n         -9.4338e-02, -1.1502e-01,  4.7658e-02, -1.3702e-01, -1.5861e-02,\n          1.8004e-01,  1.8338e-01,  1.3237e-01, -2.5729e-02, -1.2154e-02,\n         -1.5256e-01,  7.8170e-02,  1.7213e-01,  1.3814e-01],\n        [ 1.6132e-01,  2.4467e-02, -2.3652e-02,  2.0098e-01,  3.7442e-03,\n          5.1859e-02, -1.9294e-01,  2.1351e-02, -7.6952e-02,  1.9774e-01,\n         -1.0056e-01,  4.7446e-02,  1.2641e-01,  1.5933e-01,  1.4917e-01,\n          2.3587e-02, -1.3805e-01, -1.9129e-01,  1.9560e-01, -1.3578e-01,\n         -9.7528e-02, -1.6894e-01,  1.8890e-01, -1.0372e-01],\n        [ 5.5659e-02, -1.0005e-01,  6.0959e-02, -1.1076e-01, -4.8614e-02,\n         -9.4759e-02,  5.8781e-02, -1.5543e-01, -1.8615e-01, -1.9685e-01,\n         -1.9031e-01,  5.0378e-02, -2.2406e-02, -1.0250e-01,  1.2125e-01,\n          1.1346e-01,  9.0510e-02,  1.2289e-01,  6.4259e-02, -1.4314e-01,\n          1.1012e-01, -3.4363e-02, -9.2365e-02, -6.2662e-02],\n        [ 1.4096e-01,  1.9086e-02,  1.3654e-01,  6.8780e-02,  8.9750e-02,\n         -1.2268e-03, -1.9014e-01, -4.1401e-04,  5.5507e-03, -1.2381e-01,\n         -1.1370e-01,  1.2536e-01,  1.1246e-01,  2.6122e-02,  8.1245e-03,\n          1.2953e-01, -1.3411e-01,  6.1899e-02, -1.8285e-01, -2.5249e-02,\n         -7.6291e-02,  1.4007e-01,  4.2863e-02, -4.1487e-02]],\n       requires_grad=True)\n\n&gt; WeightParam size: torch.Size([24])\n&gt; Parameter containing:\ntensor([ 0.1955, -0.1343, -0.1572,  0.0292,  0.1994,  0.1983, -0.1607, -0.1858,\n        -0.1900, -0.0327, -0.0178,  0.0808,  0.0426, -0.1548,  0.1641, -0.0954,\n         0.1519,  0.0497,  0.1579, -0.0098, -0.0063,  0.0672, -0.0441,  0.1977],\n       requires_grad=True)\n\n"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mpNqT4YmoCGg","tags":[],"colab":{},"executionInfo":{"status":"ok","timestamp":1600986123594,"user_tz":300,"elapsed":291,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# # get the training data for DGL\n","# def get_xy(index):\n","#     tempx = np.array([np.transpose(x_train)[index]])\n","#     x_train_one = torch.from_numpy(tempx).float()\n","#     x_train_one = x_train_one.transpose(0, 1)\n","\n","#     tempy = np.array([np.transpose(y_train)[index]])\n","#     y_train_one = torch.from_numpy(tempy).float()\n","#     y_train_one = y_train_one.transpose(0, 1)\n","\n","#     return x_train_one, y_train_one"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"0lEyJ6L0K7Gs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1600986125262,"user_tz":300,"elapsed":436,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"8083b12e-b83a-449d-b397-7550340b3ff8"},"source":["# Set the ratio of training/test set\n","train_ratio = 0.8\n","n_train = int(np.floor(train_ratio * n_sample))\n","n_test = n_sample - n_train\n","print(\n","    \"Data set size: {}\\n > Training set size: {}\\n > Test set size: {}\".format(\n","        n_sample, n_train, n_test\n","    )\n",")\n"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"Data set size: 6000\n &gt; Training set size: 4800\n &gt; Test set size: 1200\n"}]},{"cell_type":"code","metadata":{"tags":[],"id":"LRztRSjSK7Gt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600986127497,"user_tz":300,"elapsed":302,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"6670ae21-875f-40e3-ad64-07a492b52653"},"source":["# Generate training set and test set\n","x_train2, x_test2, y_train2, y_test2 = train_test_split(\n","    load_data[0:n_bus, :].transpose(),\n","    y0[:, 0:n_sample].transpose(),\n","    test_size=0.2,\n","    random_state=22,\n",")\n","x_train = x_train2.transpose()\n","y_train = y_train2.transpose()\n","x_test = x_test2.transpose()\n","y_test = y_test2.transpose()\n","# x_train = load_data[0:n_bus,0:n_train].copy()\n","# y_train = bound_idx[:,0:n_train].copy()\n","# x_test = load_data[0:n_bus,n_train:n_sample].copy()\n","# y_test = bound_idx[:,n_train:n_sample].copy()\n","print(\"x_train shape: {}\".format(x_train.shape))\n","print(\"y_train shape: {}\".format(y_train.shape))\n","print(\"x_test shape: {}\".format(x_test.shape))\n","print(\"y_test shape: {}\".format(y_test.shape))\n","\n"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":"x_train shape: (24, 4800)\ny_train shape: (24, 4800)\nx_test shape: (24, 1200)\ny_test shape: (24, 1200)\n"}]},{"cell_type":"code","metadata":{"tags":[],"id":"gMevgRCFK7Gv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986129163,"user_tz":300,"elapsed":288,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# tempx = np.array([np.transpose(x_train)[0]])\n","# x_train_one = torch.from_numpy(tempx).float()\n","# x_train_one = x_train_one.transpose(0, 1)\n","# print(x_train_one.shape)\n","\n","\n","# tempy = np.array([np.transpose(y_train)[0]])\n","# y_train_one = torch.from_numpy(tempy).float()\n","# y_train_one = y_train_one.transpose(0, 1)\n","# print(y_train_one.shape)\n","# print('Training data size:',x_train.shape)\n","# print('Training label size:',y_train.shape)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"jaKFE2FAK7Gx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600986130011,"user_tz":300,"elapsed":311,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"3fd60340-fd2c-40ee-a19c-af5fd6714806"},"source":["# generate torch y_train for concatenated obj\n","y_train1 = torch.from_numpy(y_train)  # .float()\n","# expand into 3d tensor\n","y_train1.unsqueeze_(-1)\n","y_train1 = y_train1.expand(n_bus, n_train, 1)\n","y_train1 = y_train1.transpose(2, 1)\n","print(y_train1.shape)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([24, 1, 4800])\n"}]},{"cell_type":"code","metadata":{"id":"uV19fLzBK7G0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986131946,"user_tz":300,"elapsed":247,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":[""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jmgEZ0HK7G1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986132641,"user_tz":300,"elapsed":250,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["class Dataset(torch.utils.data.Dataset):\n","    \"\"\"Optimal Power Flow Dataset.\n","    \"\"\"\n","\n","    def __init__(self, features, labels):\n","        \"\"\"Initialization.\n","        \n","        Args:\n","            features (numpy.ndarray): feature data.\n","            labels (numpy.ndarray): label data.\n","        \"\"\"\n","        self.features = np.transpose(features)\n","        self.labels = np.transpose(labels)\n","\n","    def __len__(self):\n","        \"\"\"Denotes the total number of samples.\n","\n","        Returns:\n","            int: data length.\n","        \"\"\"\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Generates one sample of data\n","\n","        Args:\n","            idx ([type]): [description]\n","\n","        Returns:\n","            [type]: [description]\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        # Select sample\n","        X = self.features[idx]\n","        y = self.labels[idx]\n","\n","        print(X.shape)\n","        print(y.shape)\n","\n","        return X, y"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_Tj30JrK7G3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986134681,"user_tz":300,"elapsed":662,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# device option setting\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","if use_cuda:\n","    G = G.to(device)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvkRjidhK7G5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986143987,"user_tz":300,"elapsed":250,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# hyper param setting\n","params = {'batch_size': 1,\n","          'shuffle': True,\n","          'num_workers': 3}\n","\n","accumulation_steps = 100\n","max_epochs = 5"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tPGPrVhK7G7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986148736,"user_tz":300,"elapsed":335,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# Dataset Generators\n","training_set = Dataset(features=x_train, labels=y_train)\n","training_generator = torch.utils.data.DataLoader(training_set, **params)\n","\n","validation_set = Dataset(features=x_test, labels=y_test)\n","validation_generator = torch.utils.data.DataLoader(validation_set, **params)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-KVAUxfK7G8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600986153810,"user_tz":300,"elapsed":313,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}}},"source":["# set loss_func & optimizer\n","loss_func = F.mse_loss\n","optimizer = torch.optim.Adam(net.parameters())\n","loss_optm = []\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7uHUoHNZoCGq","tags":[],"colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"error","timestamp":1600986210954,"user_tz":300,"elapsed":430,"user":{"displayName":"Jeehyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLnJWIi0DBeSTx-F-lUp3D372cIjUlDUjMH6iuNQ=s64","userId":"11967533796373476523"}},"outputId":"65a26a9c-3d27-4ed8-cf89-97fe6b5efc43"},"source":["for epoch in range(max_epochs):\n","    # training loop\n","    for local_batch, local_labels in training_generator:\n","        # Transfer to GPU\n","        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","\n","        print(local_batch.shape)\n","\n","        # net.train() # ???\n","        logits = net(G_cuda, I_bus, local_batch) # I_bus ???\n","\n","        \n","        loss = loss_func(logits, local_labels)  # / accumulation_steps\n","        loss.backward()\n","\n","        if ((sample + 1) % accumulation_steps) == 0:\n","            optimizer.step()  # update parameters of net\n","            optimizer.zero_grad()  # clear the psat gradient\n","\n","    # test for simple adaptive scheme\n","    # if epoch > 10:\n","    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.15)\n","    # if epoch > 10:\n","    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.04)\n","    # if epoch > 20:\n","    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.03)\n","    # if epoch > 30:\n","    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\n","    # if epoch > 40:\n","    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n","\n","    # # Decay Learning Rate\n","    # if epoch > 1:\n","    #   scheduler.step()\n","\n","    print(\"Epoch %d | Loss: %.4f\" % (epoch, loss.item()))\n","    loss_optm.append(loss.item())\n","\n","    # validation loop\n","    with torch.set_grad_enabled(False):\n","        pass\n"],"execution_count":27,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m&lt;ipython-input-27-07783baba49e&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Transfer to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 737\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m&#39;daemonic processes are not allowed to have children&#39;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;wb&#39;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LSw7m9Tos9MH","tags":[],"colab":{},"outputId":"72dcd9c7-1a9c-4066-f3ca-fe9d0cdb82c0"},"source":["ep_range1 = 5\n","\n","for epoch in range(ep_range1):\n","    # print('Epoch:', epoch,'LR:', scheduler.get_lr())\n","    for sample in range(n_train):\n","        x_train_one, y_train_one = get_xy(sample)\n","        net.train()\n","        logits = net(G, I_bus, x_train_one)\n","        # loss = F.binary_cross_entropy(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n","        # loss = F.mse_loss(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n","        loss = F.mse_loss(logits, y_train_one)  #/ accumulation_steps\n","        loss.backward()\n","\n","        if ((sample + 1) % accumulation_steps) == 0:\n","            optimizer.step()  # update parameters of net\n","            optimizer.zero_grad()  # clear the psat gradient\n","\n","    print('Epoch %d | Loss: %.4f' % (epoch + ep_range + 1, loss.item()))\n","    loss_optm.append(loss.item())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zZ0nLutzpyHX"},"source":["## Optimization methods:\n","**We need to incorporate batch size into the optimization step size for mini batches.** \n","- **Rprop:** A gradient descent algorithm that only uses the signs of gradients to compute updates. It stands for Resilient Propagation and works well in many situations because it adapts the step size dynamically for each weight independently.\n","- **Learning rate scheduling:** used with optimizers\n","- **lr_scheduler.StepLR:** Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/\n","- **lr_scheduler.CyclicLR:** Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR). The policy cycles the learning rate between two boundaries with a constant frequency. Cyclical learning rate policy changes the learning rate after every batch. step should be called after a batch has been used for training."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pfTSSX29R7jP","colab":{},"outputId":"97708d82-7e33-46ea-b189-7fdff8e7cc45"},"source":["plt.figure()\n","plot_idx = np.arange(np.size(loss_optm))\n","plt.plot(plot_idx[3:-1],loss_optm[3:-1],lw=2,label='loss level')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show(block=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iF-gZIOko2Jd"},"source":["## Step 4. Validation\n","**Validate the trained model using the test set**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2uCp3fEEFGCv"},"source":["When a model is trained, we can use the following method to evaluate the performance of the model on the test dataset:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nrhVrVUb0d2t","tags":[],"colab":{},"outputId":"0bfca9ea-a2c8-4931-a47a-31c356035082"},"source":["# Generate one data pt. for testing the trained model\n","def get_xy_test(index):\n","    tempx=np.array([np.transpose(x_test)[index]])\n","    x_train_one=torch.from_numpy(tempx).float()\n","    x_train_one=x_train_one.transpose(0,1)\n","\n","    tempy=np.array([np.transpose(y_test)[index]])\n","    y_train_one=torch.from_numpy(tempy).float()\n","    y_train_one=y_train_one.transpose(0,1)\n","\n","    return x_train_one,y_train_one\n","\n","# generate torch y_train for concatenated obj\n","y_test1 = torch.from_numpy(y_test)#.float()\n","# expand into 3d tensor \n","y_test1.unsqueeze_(-1)\n","y_test1 = y_test1.expand(n_bus,n_test,1)\n","y_test1 = y_test1.transpose(2,1)\n","print(y_test1.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([24, 1, 1200])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C5PBICs8E51B","colab":{}},"source":["# model evaluation function\n","def evaluate(model, g, features, labels, n, I):\n","    model.eval()\n","    with torch.no_grad():\n","      indices = torch.tensor(np.zeros((n_bus,1,n)))\n","      for sample in range(n):\n","        x_sample,y_sample=get_xy_test(sample)\n","        logits = model(g, I, x_sample)\n","        logp = logits\n","        # logp = torch.sigmoid(logits)\n","        # logp = F.log_softmax(logits, 1)\n","        # _, indices1 = torch.max(logp, dim=1)\n","        indices[:,:,sample] = logp.clone()\n","\n","      # correct = torch.sum(indices == labels)\n","      # return correct.item() * 1.0 / len(labels)\n","      return indices"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L5VvNfm_cFMD","tags":[],"colab":{},"outputId":"5d7c203a-b79d-4710-9929-4f5aabdc0b34"},"source":["print(x_test.shape)\n","print(y_test1.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(24, 1200)\n","torch.Size([24, 1, 1200])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YrE4bhDc64fK","colab":{}},"source":["# make predictions\n","indices = evaluate(net, G, x_test, y_test1,n_test, I_bus)\n","# test_acc = evaluate(net, G, x_test, y_test1,n_test)\n","# print(\"Epoch_last {:05d} | Loss {:.4f} | Test Acc {:.4f}\".format(epoch, loss.item(), test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S7QRkoh8b1cm","tags":[],"colab":{},"outputId":"3c0f7c32-08d2-4868-e6ee-93913c65d37b"},"source":["y_test0 = y_test1.numpy().copy()\n","y_pred0 = indices.numpy().copy()\n","\n","L_infty_err = []\n","L1_err = []\n","for i in range(n_test):\n","  L_infty_err.append(np.max(np.abs(y_test0[:,:,i]-y_pred0[:,:,i])))\n","  L1_err.append(np.sum(np.abs(y_test0[:,:,i]-y_pred0[:,:,i])))\n","print('L_infty mean: ',np.mean(L_infty_err))\n","print('L_1 mean: ',np.mean(L1_err))\n"," \n","val, idx = min((val, idx) for (idx, val) in enumerate(L_infty_err))\n","print(val,idx)\n","# print('L_inf sample: \\n',y_test[:,:,idx])\n","# print(y_pred[:,:,idx])\n","val1, idx1 = min((val, idx) for (idx, val) in enumerate(L1_err))\n","print(val1,idx1)\n","# print('L1 sample: \\n',y_test[:,:,idx1])\n","# print(y_pred[:,:,idx1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["L_infty mean:  0.4356632132296591\n","L_1 mean:  1.5227703809037367\n","0.05828738212585449 29\n","0.45503627965421556 1117\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CW9qX0nGgoS_","tags":[],"colab":{},"outputId":"cce15751-dc6a-46fc-e397-2d60fe85dd22"},"source":["print(load_data[0:n_bus,:].shape)\n","print(y0[0:n_bus,0:n_sample].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(24, 6000)\n","(24, 6000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3pQ1v0b58NRH","colab":{}},"source":["# Save the predictions for other training/evaluation jobs\n","\n","\n","# import pprint\n","# from os import path\n","#\n","# from datetime import datetime\n","# from packaging import version\n","\n","def save_dataset(test_case, dataset):\n","    file_name = test_case.split('.')[0]\n","    file_path = 'drive/My Drive/gnn/numerical_results/'\n","    file_dir = file_path + file_name + '.pickle'\n","    outfile = open(file_dir, 'wb')\n","    pickle.dump(dataset, outfile)\n","    outfile.close()\n","\n","def get_xy_eval(index):\n","    tempx=np.array([np.transpose(load_data[0:n_bus,:])[index]])\n","    x_train_one=torch.from_numpy(tempx).float()\n","    x_train_one=x_train_one.transpose(0,1)\n","\n","    return x_train_one\n","\n","def model_eval(model, g, features, n, I):\n","    model.eval()\n","    with torch.no_grad():\n","      indices = torch.tensor(np.zeros((n_bus,1,n)))\n","      for sample in range(n):\n","        x_sample=get_xy_eval(sample)\n","        logits = model(g, I, x_sample)\n","        logp = logits\n","        indices[:,:,sample] = logp.clone()\n","\n","      return indices\n","\n","indices = model_eval(net, G, load_data[0:n_bus,:], n_sample, I_bus)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NdH_Svt5js05","colab":{},"outputId":"a4ed17e4-788c-4456-9f7d-121b78c01764"},"source":["# generation prediction by GNN model\n","print(indices.shape)\n","gen_pred_norm = indices.numpy().copy()\n","\n","y0[j,i] = np.divide(gen_exact[j,i]-gen_low_limit[j],gen_up_limit[j]-gen_low_limit[j])\n","\n","gen_pred = np.zeros((n_bus,n_sample))\n","for i in range(n_sample):\n","  for j in range(n_bus):\n","    gen_pred[j,i] = indices[j,0,i] * (gen_up_limit[j]-gen_low_limit[j]) + gen_low_limit[j]\n","\n","dataset = {'pred': gen_pred}\n","# print(dataset)\n","filename = 'GNN_24bus_gen_prediction_copy_new'\n","save_dataset(filename, dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([24, 1, 6000])\n"],"name":"stdout"},{"output_type":"stream","text":["/Users/jeehyunpark/anaconda3/envs/GNN4OPF/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'drive/My Drive/gnn/numerical_results/GNN_24bus_gen_prediction_copy_new.pickle'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-91d84198b4fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'GNN_24bus_gen_prediction_copy_new'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msave_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-a3117fbc61ed>\u001b[0m in \u001b[0;36msave_dataset\u001b[0;34m(test_case, dataset)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/My Drive/gnn/numerical_results/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfile_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/gnn/numerical_results/GNN_24bus_gen_prediction_copy_new.pickle'"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lZ5hVfqjde3z","colab":{}},"source":["for i in range(10):\n","  print(np.sum(x_train[:,i]),np.sum(gen_pred[:,i]))\n","# print(np.sum(gen_pred[:,1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0h31WYc4LtTG","colab":{}},"source":["# Evaluate the prediction accuracy by relative error\n","acc_threshold1 = 0.05\n","acc_threshold = 0.1\n","\n","acc_count = 0\n","acc_count1 = 0\n","for i in range(24):\n","  if np.abs(y_test0[i,:,idx]) > 0:\n","    if np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx])/np.abs(y_test0[i,:,idx]) < acc_threshold or np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx]) < acc_threshold1:\n","        acc_count = acc_count+1\n","    if np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1])/np.abs(y_test0[i,:,idx1]) < acc_threshold or np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1]) < acc_threshold1:\n","        acc_count1 = acc_count1+1\n","  else:\n","    if np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx]) < acc_threshold1:\n","        acc_count = acc_count+1\n","    if np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1]) < acc_threshold1:\n","        acc_count1 = acc_count1+1\n","print('most accurate L_inf: ',acc_count,'  L_1: ',acc_count1)\n","\n","\n","acc_test = np.zeros(y_test0.shape[0])\n","for j in range(y_test0.shape[0]):\n","  acc_count = 0\n","  for i in range(24):\n","    if np.abs(y_test0[i,:,j]) > 0:\n","      if np.abs(y_test0[i,:,j]-y_pred0[i,:,j])/np.abs(y_test0[i,:,j]) < acc_threshold or np.abs(y_test0[i,:,j]-y_pred0[i,:,j]) < acc_threshold1:\n","          acc_count = acc_count+1\n","    else:\n","      if np.abs(y_test0[i,:,j]-y_pred0[i,:,j]) < acc_threshold1:\n","          acc_count = acc_count+1\n","  acc_test[j] = acc_count\n","print('Mean accuracy: ',np.mean(acc_test)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SzHeOYpbIZ41","colab":{}},"source":["\n","# for i in range(3):\n","  # print('Prediction:',indices[:,:,i].transpose(0,1))\n","  # print('Ture label:',y_test1[:,:,i].transpose(0,1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eu4vxBiiG7IN"},"source":["## Data visualization"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kZIQUKv3G42U","colab":{}},"source":["def result_reshape(data):\n","    result_dim = math.ceil(math.sqrt(len(data)))\n","    reshaped_data = np.zeros((result_dim, result_dim))\n","\n","    for i in range(result_dim):\n","        for j in range(result_dim):\n","            try:\n","                reshaped_data[i][j] = data[result_dim * i + j]\n","            except IndexError:\n","                reshaped_data[i][j] = -1\n","    return reshaped_data\n","\n","\n","def test_vs_pred(y_test, y_pred,  data_idx, test_case):\n","    y_test0 = y_test[:,:,data_idx]\n","    y_pred0 = y_pred[:,:,data_idx]\n","    y_test_reshaped = result_reshape(y_test0)\n","    y_pred_reshaped = result_reshape(y_pred0)\n","\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n","\n","    fig.suptitle('Active Constraints Distribution: ' + test_case.split('.')[0], size=19, y=0.88)\n","    axes[0].set_title('y_test', size=15, y=1.03)\n","    axes[1].set_title('y_pred', size=15, y=1.03)\n","    # axes[2].set_title('y_pred_binary', size=15, y=1.03)\n","\n","    sns.heatmap(y_test_reshaped,\n","                xticklabels=False,\n","                yticklabels=False,\n","                cbar_kws={'ticks': [-1, 0, 1], 'shrink': .75},\n","                square=True,\n","                ax=axes[0])\n","\n","    sns.heatmap(y_pred_reshaped,\n","                xticklabels=False,\n","                yticklabels=False,\n","                cbar_kws={'ticks': [-1, 0, 1], 'shrink': .75},\n","                square=True,\n","                ax=axes[1])\n","    \n","\n","    fig.show()\n","    # file_dir = path.join('drive/My Drive/OPF_Porject_EE394V_SPR2020-master/codes/experiments/figures/', test_case.split('.')[0] + '.png')\n","    # fig.savefig(file_dir, format='png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wrfl_miqWLip","colab":{}},"source":["print(y_test1[:,:,1].transpose(0,1))\n","print(indices[:,:,1].transpose(0,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LNlT68rcHGHV","colab":{}},"source":["# y_test1.resize_((n_bus+n_line,n_test))\n","# indices_int.resize_((n_bus+n_line,n_test))\n","# indices.resize_((n_bus+n_line,n_test))\n","\n","test_cases = [\n","    'pglib_opf_case24_ieee_rts.pickle', \n","]\n","\n","data_idx = [7,10,33,55,64,78,96]\n","data_idx = np.arange(10)\n","# test_vs_pred(y_test, y_pred, data_idx, test_cases[case_idx])\n","for i in range(len(data_idx)):\n","  test_vs_pred(y_test1, indices, data_idx[i], test_cases[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"VZwAs8psK7Hg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}