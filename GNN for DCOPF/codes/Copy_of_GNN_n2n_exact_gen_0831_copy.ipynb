{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of GNN_n2n_exact_gen_0831_copy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ1P8LLwoCB-"
      },
      "source": [
        "# GNN for Optimal Generation Dispatch\n",
        "## IEEE 24-bus RTS system \n",
        "* System settings: 24 buses, 34 lines (concatenated from 38), 17 loads, 12 generating units on 10 buses.\n",
        "* Data: Currently we use a dataset with ~ 6000 samples, 80% used for training and 20% for validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOjKm_RBoCCA"
      },
      "source": [
        "Step 1: Creating a graph in DGL\n",
        "-------------------------------\n",
        "* Load necessary packages.\n",
        "* Read the data and create the graph for the system:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM9Zk1p9oOXU",
        "outputId": "49ffb7a2-d671-4375-be62-cd3e8c7d5ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "tags": []
      },
      "source": [
        "!pip install dgl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: dgl in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (0.5.1)\nRequirement already satisfied: networkx&gt;=2.1 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from dgl) (2.5)\nRequirement already satisfied: scipy&gt;=1.1.0 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from dgl) (1.5.0)\nRequirement already satisfied: requests&gt;=2.19.0 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from dgl) (2.24.0)\nRequirement already satisfied: numpy&gt;=1.14.0 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from dgl) (1.19.1)\nRequirement already satisfied: decorator&gt;=4.3.0 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from networkx&gt;=2.1-&gt;dgl) (4.4.2)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;dgl) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;dgl) (1.25.10)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;dgl) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/jeehyunpark/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;dgl) (2020.6.20)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ozf8r2noil-",
        "outputId": "cde76a4d-0413-46de-f16a-0e31b6490f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKLovDeXoCCP",
        "outputId": "97974377-c2a8-4a80-9f30-8a4d8a8a0b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "tags": []
      },
      "source": [
        "# Import necessary packages\n",
        "import dgl # graph convolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Using backend: pytorch\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RamArMRLoCC7"
      },
      "source": [
        "# load the data files\n",
        "# filename = './drive/My Drive/Colab Notebooks/ieee24_rts_6183exact_0831.txt' # active level 0.1024(line0.0124), max active line 3\n",
        "# data = pd.read_table(filename,sep=',',header=None).to_numpy()\n",
        "\n",
        "# @ Local env\n",
        "filename = '../data/ieee24_rts_6183exact_0831.txt'  # active level 0.1024(line0.0124), max active line 3\n",
        "data = pd.read_table(filename, sep=',', header=None).to_numpy()\n",
        "\n",
        "# system size\n",
        "n_bus  = int(data[0,0].copy())\n",
        "n_line  = int(data[1,0].copy())\n",
        "n_load  = int(data[2,0].copy())\n",
        "n_sample  = int(data[3,0].copy())\n",
        "\n",
        "# line connection\n",
        "line_bus = data[:,1:3].copy()\n",
        "\n",
        "# load and corresponding line data\n",
        "load_data0 = data[:,3:n_sample+3].copy()\n",
        "line_flow = data[:,n_sample + 3 : 2*n_sample + 3].copy()\n",
        "bound_idx_low = data[:,2*n_sample + 3 : 3*n_sample + 3].copy()\n",
        "bound_idx_up = data[:,3*n_sample + 3 : 4*n_sample + 3].copy()\n",
        "bound_idx0 = bound_idx_up + bound_idx_low # may use 'np.add(a,-b)' instead\n",
        "line_limit = data[:,4*n_sample + 3].copy()\n",
        "# print(line_limit)\n",
        "\n",
        "# generation data\n",
        "gen_exact = data[:,4*n_sample + 4 : 5*n_sample + 4].copy()\n",
        "gen_low_limit = data[:,5*n_sample + 4].copy()\n",
        "gen_up_limit = data[:,5*n_sample + 5].copy()\n",
        "\n",
        "# normalize the generation data\n",
        "y0 = np.zeros((n_bus,n_sample))\n",
        "for i in range(n_sample):\n",
        "  # y0[:,i] = np.divide(line_flow[:,i],line_limit) # w/ direction\n",
        "  for j in range(n_bus):\n",
        "    if gen_up_limit[j] > 0:\n",
        "      y0[j,i] = np.divide(gen_exact[j,i]-gen_low_limit[j],gen_up_limit[j]-gen_low_limit[j])\n",
        "    else:\n",
        "      y0[j,i] = 0\n",
        "\n",
        "  \n",
        "\n",
        "# % exact generation\n",
        "# data1(1:N,4*n+5:5*n+4) = gen_data;\n",
        "# % generation lower bound & upper bound\n",
        "# data1(1:N,5*n+5) = g_min;\n",
        "# data1(1:N,5*n+6) = g_max;\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzgofvUMT1G-",
        "outputId": "6a466615-0404-4548-f84d-25460e1b0ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "tags": []
      },
      "source": [
        "print(np.max(y0)) # check the normalization\n",
        "print(np.min(y0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1.0\n0.0\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfMmqGJmru9O",
        "outputId": "fc70e9a5-0ea1-48d8-e8ad-23b059941106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "tags": []
      },
      "source": [
        "# Use partial data for faster test\n",
        "n_sample = 6000\n",
        "\n",
        "load_data = load_data0[:,:n_sample].copy()\n",
        "bound_idx = bound_idx0[:,:n_sample].copy()*1\n",
        "\n",
        "# gen_idx_low = gen_idx_low[:,:n_sample]\n",
        "# gen_idx_up = gen_idx_up[:,:n_sample]\n",
        "# gen_idx = gen_idx_up + gen_idx_low\n",
        "\n",
        "# print system info\n",
        "print('Test case: ',filename)\n",
        "print('Number of buses: ',n_bus)\n",
        "print('Number of lines: ',n_line)\n",
        "print('Number of loads: ',n_load)\n",
        "print('Number of samples: ',n_sample)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test case:  ../data/ieee24_rts_6183exact_0831.txt\nNumber of buses:  24\nNumber of lines:  34\nNumber of loads:  17\nNumber of samples:  6000\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf9YAQgToCEO"
      },
      "source": [
        "* Generate and visualize the DGL graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxaGvjWGoCEH"
      },
      "source": [
        "# Graph generating function\n",
        "def build_system_graph(src,dst):\n",
        "    # Edges are directional in DGL; Make them bi-directional.\n",
        "    # Matlab counts from 1 and python from 0\n",
        "    u = np.concatenate([src, dst])-1 \n",
        "    v = np.concatenate([dst, src])-1\n",
        "    # Construct a DGLGraph\n",
        "    return dgl.DGLGraph((u, v))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3zws2wBoCEd",
        "outputId": "b7733abf-c464-44a0-8587-417946b069c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "tags": []
      },
      "source": [
        "line_src = line_bus[:,0].copy().astype(int)\n",
        "line_dst = line_bus[:,1].copy().astype(int)\n",
        "G = build_system_graph(line_src,line_dst)\n",
        "print('There are %d nodes.' % G.number_of_nodes())\n",
        "print('There are %d edges.' % G.number_of_edges())\n",
        "\n",
        "import networkx as nx\n",
        "# Since the actual graph is undirected, we convert it for visualization\n",
        "# purpose.\n",
        "# nx_G = G.to_networkx().to_undirected()\n",
        "# # Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n",
        "# pos = nx.kamada_kawai_layout(nx_G)\n",
        "# nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "There are 24 nodes.\nThere are 68 edges.\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLmJ64bCoCFJ"
      },
      "source": [
        "Step 2: Assign features to nodes, edges\n",
        "--------------------------------------------\n",
        "e.g.: Graph neural networks associate features with nodes and edges for training.\n",
        "\n",
        "* In our case, inputs on nodes, features on egdes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xqplmGwoCFe"
      },
      "source": [
        "# # In DGL, you can add features for all nodes at once, using a feature tensor that\n",
        "# # batches node features along the first dimension. The code below adds the learnable\n",
        "# # embeddings for all nodes:\n",
        "\n",
        "# embed_feature = 10\n",
        "# embed = nn.Embedding(G.number_of_edges(), embed_feature)  \n",
        "# # 68 edges with embedding dim equal to 10 for edge classification\n",
        "# G.edata['feat'] = embed.weight"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHOzg-9PoCF3"
      },
      "source": [
        "Step 3: Define a Graph Convolutional Network (GCN) and Train the model\n",
        "--------------------------------------------------\n",
        "To perform node classification, use the Graph Convolutional Network\n",
        "(GCN) developed by `Kipf and Welling <https://arxiv.org/abs/1609.02907>`_. Here\n",
        "is the simplest definition of a GCN framework. We recommend that you \n",
        "read the original paper for more details.\n",
        "\n",
        "- At layer $l$, each node $v_i^l$ carries a feature vector $h_i^l$.\n",
        "- Each layer of the GCN tries to aggregate the features from $u_i^{l}$ where\n",
        "  $u_i$'s are neighborhood nodes to $v$ into the next layer representation at\n",
        "  $v_i^{l+1}$. This is followed by an affine transformation with some\n",
        "  non-linearity.\n",
        "\n",
        " **In this project we use weighted graph convolution and weights are \n",
        "learned during the trainning process.**\n",
        "\n",
        "The above definition of GCN fits into a **message-passing** paradigm: Each\n",
        "node will update its own feature with information sent from neighboring\n",
        "nodes. A graphical demonstration is displayed below.\n",
        "\n",
        "\n",
        "In DGL, we provide implementations of popular Graph Neural Network layers under\n",
        "the `dgl.<backend>.nn` subpackage. The :class:`~dgl.nn.pytorch.GraphConv` module\n",
        "implements one Graph Convolutional layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBIgnqqtoCGB"
      },
      "source": [
        "**In our case, we want to perform edge classification based on feature inputs from nodes.**\n",
        "* Thus we need to redesign the GNN to map the features from node to deges\n",
        "* Define a deeper GCN model that contains two GCN layers:\n",
        "\n",
        "We first try convolutions on the nodes first then map to edges then try mapping to edges first then do convolutions on edges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2fkZxWsoCGP"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from dgl.nn.pytorch.conv import GraphConv\n",
        "\n",
        "\n",
        "# One layer Graph convolution from nodes to edges\n",
        "class Graph_convolution_v2e(nn.Module):\n",
        "    def __init__(self, in_features, out_features, W, bias=True):\n",
        "        super(Graph_convolution_v2e, self).__init__()\n",
        "        #         self.Weight=nn.Parameter(torch.Tensor(W))\n",
        "        #         self.Weight=nn.Parameter(torch.from_numpy(W))\n",
        "        self.register_buffer(\"w\", torch.from_numpy(W).float())\n",
        "        #         for temp in self.Weight:\n",
        "        #             temp.requires_grad=False\n",
        "        #         self.Weight = self.Weight.detach()\n",
        "        self.scale = nn.Parameter(torch.Tensor(out_features, 1))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features, 1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # print(input.shape)\n",
        "        # print(self.scale.shape)\n",
        "        h = torch.matmul(Variable(self.w), input)\n",
        "        return torch.mul(h, self.scale) + self.bias\n",
        "\n",
        "\n",
        "# Need to change that to our case: 2 networks, one node clustering (or double it as in the reference),\n",
        "# one node to edge.\n",
        "\n",
        "# Set dummy bus signals as zero\n",
        "I_bus = np.identity(n_bus)\n",
        "idx = [2, 3, 4, 5, 7, 8, 9, 10, 11, 16, 18, 19, 23]\n",
        "for i in range(len(idx)):\n",
        "    I_bus[idx, idx] = 0\n",
        "I_bus = torch.from_numpy(I_bus).float()\n",
        "\n",
        "# GNN using DGL v2v graph convolution and our own v2e graph convolution\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_size, num_nodes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(\n",
        "            in_feats,\n",
        "            hidden_size[0],\n",
        "            norm=\"both\",\n",
        "            weight=True,\n",
        "            bias=True,\n",
        "            activation=None,\n",
        "        )\n",
        "        # norm='both', weight=True, bias=True, activation=None\n",
        "        self.conv2 = GraphConv(\n",
        "            hidden_size[0],\n",
        "            hidden_size[1],\n",
        "            norm=\"both\",\n",
        "            weight=True,\n",
        "            bias=True,\n",
        "            activation=None,\n",
        "        )\n",
        "        self.conv3 = GraphConv(\n",
        "            hidden_size[1],\n",
        "            hidden_size[2],\n",
        "            norm=\"both\",\n",
        "            weight=True,\n",
        "            bias=True,\n",
        "            activation=None,\n",
        "        )\n",
        "        self.conv4 = GraphConv(\n",
        "            hidden_size[2],\n",
        "            hidden_size[3],\n",
        "            norm=\"both\",\n",
        "            weight=True,\n",
        "            bias=True,\n",
        "            activation=None,\n",
        "        )\n",
        "        self.conv5 = GraphConv(\n",
        "            hidden_size[3],\n",
        "            hidden_size[4],\n",
        "            norm=\"both\",\n",
        "            weight=True,\n",
        "            bias=True,\n",
        "            activation=None,\n",
        "        )\n",
        "        self.conv6 = GraphConv(\n",
        "            hidden_size[4],\n",
        "            hidden_size[5],\n",
        "            norm=\"both\",\n",
        "            weight=True,\n",
        "            bias=True,\n",
        "            activation=None,\n",
        "        )\n",
        "        # self.conv7 = GraphConv(hidden_size[5], hidden_size[6],norm='both', weight=True, bias=True, activation=None)\n",
        "        # self.conv8 = GraphConv(hidden_size[6], hidden_size[7],norm='both', weight=True, bias=True, activation=None)\n",
        "        # self.conv9 = GraphConv(hidden_size[7], hidden_size[8],norm='both', weight=True, bias=True, activation=None)\n",
        "        # self.conv3 = Graph_convolution_v2e(hidden_size[1], num_edges, W)\n",
        "        #         self.W = W\n",
        "\n",
        "        self.lin_output = nn.Linear(num_nodes, num_nodes)\n",
        "\n",
        "    def forward(self, g, inputs):  # g is the graph stored in DGL\n",
        "        # print(g)\n",
        "        # nx_G = g.to_networkx().to_undirected()\n",
        "        # pos = nx.kamada_kawai_layout(nx_G)\n",
        "        # nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])\n",
        "        # print('inputs data type:', inputs.data.type())\n",
        "        # print(inputs.shape)\n",
        "        h = self.conv1(g, inputs)\n",
        "        # h = torch.sigmoid(h)\n",
        "        # print(h.shape)\n",
        "        h = self.conv2(g, h)\n",
        "        # print(h.shape)\n",
        "        h = torch.sigmoid(h)\n",
        "        # print(h.shape)\n",
        "        h = self.conv3(g, h)\n",
        "        # h = torch.sigmoid(h)\n",
        "        h = self.conv4(g, h)\n",
        "        h = torch.sigmoid(h)\n",
        "        h = self.conv5(g, h)\n",
        "        # h = torch.sigmoid(h)\n",
        "        h = self.conv6(g, h)\n",
        "        h = torch.sigmoid(h)\n",
        "        # h = self.conv7(g, h)\n",
        "        # # h = torch.sigmoid(h)\n",
        "        # h = self.conv8(g, h)\n",
        "        # h = torch.sigmoid(h)\n",
        "        # h = self.conv9(g, h)\n",
        "        # h = torch.sigmoid(h)\n",
        "        # h = self.conv3(h)\n",
        "        # h = torch.matmul(I,h)\n",
        "        h = self.lin_output(h.transpose(0, 1)).transpose(0, 1)\n",
        "        # h = torch.matmul(I,h)\n",
        "        return h\n",
        "\n",
        "\n",
        "# net = GCN_self(n_bus, [10,10], n_line, W, W1)\n",
        "# net = GCN(n_bus, [10,10,10,10,10,10,10,1], n_line, W1)\n",
        "w_params = [40, 80, 80, 80, 80, 1]\n",
        "net = GCN(1, w_params, n_bus)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cb_xqOj9bq",
        "outputId": "cfc3cc23-efac-4e5e-84e1-0f89be2ece0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "net"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "GCN(\n  (conv1): GraphConv(in=1, out=40, normalization=both, activation=None)\n  (conv2): GraphConv(in=40, out=80, normalization=both, activation=None)\n  (conv3): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv4): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv5): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv6): GraphConv(in=80, out=1, normalization=both, activation=None)\n  (lin_output): Linear(in_features=24, out_features=24, bias=True)\n)"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data set size:  6000 , training set size:  4800 , test set size:  1200\n"
        }
      ],
      "source": [
        "# Set the ratio of training/test set\n",
        "train_ratio = 0.8\n",
        "n_train = int(np.floor(train_ratio * n_sample))\n",
        "n_test = n_sample - n_train\n",
        "print('Data set size: ',n_sample,', training set size: ',n_train,', test set size: ',n_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(24, 4800)\n(24, 4800)\n(24, 1200)\n(24, 1200)\n"
        }
      ],
      "source": [
        "# Generate training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(load_data[0:n_bus,:].transpose(), y0[:,0:n_sample].transpose(), test_size=0.2, random_state=22)\n",
        "x_train = x_train2.transpose()\n",
        "y_train = y_train2.transpose()\n",
        "x_test = x_test2.transpose()\n",
        "y_test = y_test2.transpose()\n",
        "# x_train = load_data[0:n_bus,0:n_train].copy()\n",
        "# y_train = bound_idx[:,0:n_train].copy()\n",
        "# x_test = load_data[0:n_bus,n_train:n_sample].copy()\n",
        "# y_test = bound_idx[:,n_train:n_sample].copy()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# tempx=np.array([np.transpose(x_train)[0]])\n",
        "# x_train_one=torch.from_numpy(tempx).float()\n",
        "# x_train_one=x_train_one.transpose(0,1)\n",
        "# print(x_train_one.shape)\n",
        "\n",
        "# tempy=np.array([np.transpose(y_train)[0]])\n",
        "# y_train_one=torch.from_numpy(tempy).float()\n",
        "# y_train_one=y_train_one.transpose(0,1)\n",
        "# print(y_train_one.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the training data for DGL\n",
        "def get_xy(index):\n",
        "    tempx=np.array([np.transpose(x_train)[index]])\n",
        "    x_train_one=torch.from_numpy(tempx).float()\n",
        "    x_train_one=x_train_one.transpose(0,1)\n",
        "\n",
        "    tempy=np.array([np.transpose(y_train)[index]])\n",
        "    y_train_one=torch.from_numpy(tempy).float()\n",
        "    y_train_one=y_train_one.transpose(0,1)\n",
        "\n",
        "    print(x_train_one.shape)\n",
        "    print(y_train_one.shape)\n",
        "\n",
        "    return x_train_one,y_train_one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpNqT4YmoCGg",
        "outputId": "dfa04dad-f406-4a9d-85fb-a537b77552ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "tags": []
      },
      "source": [
        "\n",
        "# generate torch y_train for concatenated obj\n",
        "y_train1 = torch.from_numpy(y_train)#.float()\n",
        "# expand into 3d tensor \n",
        "y_train1.unsqueeze_(-1)\n",
        "y_train1 = y_train1.expand(n_bus,n_train,1)\n",
        "y_train1 = y_train1.transpose(2,1)\n",
        "print(y_train1.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch.Size([24, 1, 4800])\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYRy5jCOpg7m",
        "outputId": "a7bff69e-aa89-4adc-e4a6-ca246e3c9957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": []
      },
      "source": [
        "# GNN model size\n",
        "print('Network info:',net)\n",
        "for temp in net.parameters():\n",
        "    print('Parameter',temp,'size:',temp.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Network info: GCN(\n  (conv1): GraphConv(in=1, out=40, normalization=both, activation=None)\n  (conv2): GraphConv(in=40, out=80, normalization=both, activation=None)\n  (conv3): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv4): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv5): GraphConv(in=80, out=80, normalization=both, activation=None)\n  (conv6): GraphConv(in=80, out=1, normalization=both, activation=None)\n  (lin_output): Linear(in_features=24, out_features=24, bias=True)\n)\nParameter Parameter containing:\ntensor([[ 0.3195,  0.3656,  0.0817,  0.1033, -0.2368, -0.2516,  0.2494,  0.2006,\n         -0.3399,  0.3225,  0.0794, -0.1902, -0.0399, -0.1759, -0.1665, -0.0424,\n         -0.1146,  0.2806,  0.3566,  0.1222,  0.2921,  0.0008, -0.1769, -0.3530,\n         -0.0589, -0.2981,  0.3570, -0.2600,  0.1596, -0.0371, -0.1461, -0.3215,\n          0.2758, -0.1008,  0.1450,  0.1347,  0.1848, -0.1407, -0.1820,  0.1562]],\n       requires_grad=True) size: torch.Size([1, 40])\nParameter Parameter containing:\ntensor([-0.0017,  0.0045, -0.0005, -0.0037, -0.0016,  0.0040,  0.0018, -0.0035,\n        -0.0034,  0.0042,  0.0033,  0.0020, -0.0035,  0.0030,  0.0002, -0.0043,\n         0.0037, -0.0035, -0.0039, -0.0042,  0.0035,  0.0046, -0.0039,  0.0042,\n         0.0034,  0.0036,  0.0034, -0.0041, -0.0038,  0.0046,  0.0006, -0.0028,\n        -0.0040, -0.0007,  0.0043,  0.0045, -0.0039,  0.0042,  0.0033,  0.0030],\n       requires_grad=True) size: torch.Size([40])\nParameter Parameter containing:\ntensor([[ 0.1019, -0.1660, -0.0629,  ..., -0.1637,  0.1362,  0.1888],\n        [ 0.0878, -0.0390, -0.0780,  ...,  0.0856, -0.0204, -0.0151],\n        [ 0.1113, -0.1732, -0.1408,  ...,  0.1413,  0.0158,  0.0352],\n        ...,\n        [ 0.1743, -0.1428, -0.0264,  ..., -0.0911,  0.0311, -0.0837],\n        [-0.0947, -0.0192, -0.0860,  ...,  0.0512,  0.1644,  0.0759],\n        [-0.2119,  0.1550, -0.1971,  ..., -0.0914, -0.0864,  0.0567]],\n       requires_grad=True) size: torch.Size([40, 80])\nParameter Parameter containing:\ntensor([-0.0036, -0.0042,  0.0038, -0.0030, -0.0023,  0.0038, -0.0023,  0.0037,\n         0.0037,  0.0038,  0.0041, -0.0037,  0.0038, -0.0032,  0.0038, -0.0035,\n         0.0037, -0.0031, -0.0038,  0.0014,  0.0038, -0.0043,  0.0037,  0.0038,\n         0.0044, -0.0038, -0.0037,  0.0043, -0.0038,  0.0045,  0.0042, -0.0029,\n         0.0037,  0.0039, -0.0038,  0.0035,  0.0044,  0.0022, -0.0037,  0.0043,\n        -0.0036,  0.0038,  0.0039,  0.0039,  0.0038, -0.0037, -0.0031, -0.0036,\n         0.0039, -0.0036, -0.0039, -0.0040,  0.0039, -0.0038,  0.0039,  0.0020,\n         0.0039, -0.0037,  0.0041,  0.0045, -0.0037,  0.0046, -0.0037, -0.0042,\n        -0.0036,  0.0044,  0.0038,  0.0042,  0.0039, -0.0038,  0.0038, -0.0039,\n         0.0037, -0.0038,  0.0005, -0.0038,  0.0041, -0.0038,  0.0040, -0.0035],\n       requires_grad=True) size: torch.Size([80])\nParameter Parameter containing:\ntensor([[ 0.0526,  0.0389,  0.1401,  ..., -0.1603,  0.1757,  0.0091],\n        [ 0.0124,  0.1224,  0.0129,  ..., -0.0112, -0.1290,  0.0572],\n        [-0.0300, -0.0736,  0.1179,  ..., -0.0265, -0.1016, -0.1414],\n        ...,\n        [-0.0193, -0.0437,  0.1314,  ...,  0.0095, -0.0369, -0.1395],\n        [ 0.0959, -0.1568,  0.0068,  ...,  0.0622, -0.1622,  0.0627],\n        [-0.1285, -0.0536,  0.1632,  ...,  0.0466,  0.1751,  0.1186]],\n       requires_grad=True) size: torch.Size([80, 80])\nParameter Parameter containing:\ntensor([ 3.9382e-03, -4.1519e-03,  4.1017e-03, -4.1363e-03,  4.0099e-03,\n         6.8348e-04,  2.9891e-03,  4.2678e-03, -4.3624e-03, -4.0326e-03,\n        -3.8244e-03, -3.7411e-03, -4.6329e-03,  1.8368e-03,  4.0352e-03,\n         3.9430e-03, -4.1436e-03, -3.8661e-03,  3.9266e-03,  3.7375e-03,\n         4.1130e-03, -4.0440e-03,  3.9213e-03, -4.0865e-03, -3.9556e-03,\n        -4.0657e-03, -4.1023e-03,  4.2059e-03, -3.9610e-03,  4.0325e-03,\n         3.9713e-03, -2.1928e-03, -4.5940e-03, -4.0114e-03, -3.9425e-03,\n         3.8904e-03,  3.9147e-03,  3.6914e-03,  4.0771e-03, -3.9558e-03,\n        -4.2256e-03, -4.0291e-03, -4.0093e-03, -4.0837e-03,  4.0148e-03,\n        -3.9389e-03, -1.4684e-05,  4.3256e-03, -4.2848e-03,  4.1465e-03,\n        -4.0483e-03, -3.9903e-03, -3.9039e-03,  4.0492e-03, -4.4446e-03,\n         3.4652e-03, -2.8823e-03, -4.1576e-03,  4.0009e-03,  3.9962e-03,\n        -4.0369e-03,  3.5547e-03, -3.2722e-03, -3.0956e-03, -4.1595e-03,\n        -4.0488e-03, -4.1927e-03,  3.3363e-03, -3.9688e-03,  4.0645e-03,\n         4.2721e-03, -3.7136e-03, -4.3628e-03,  4.4753e-03, -4.0083e-03,\n         1.2746e-03,  4.0512e-03, -4.0709e-03,  3.2382e-03, -8.4392e-04],\n       requires_grad=True) size: torch.Size([80])\nParameter Parameter containing:\ntensor([[-0.0745, -0.0930,  0.0528,  ..., -0.0793,  0.1843, -0.0272],\n        [ 0.1116, -0.1475,  0.0407,  ..., -0.0654, -0.1141, -0.1573],\n        [-0.0857,  0.1148, -0.0726,  ..., -0.0064,  0.1015,  0.1478],\n        ...,\n        [ 0.1283, -0.1499,  0.1364,  ...,  0.1253,  0.0147, -0.1498],\n        [ 0.1236,  0.1887,  0.0123,  ..., -0.1870, -0.0986,  0.0762],\n        [ 0.0036, -0.1777, -0.0174,  ..., -0.1116, -0.0553, -0.1135]],\n       requires_grad=True) size: torch.Size([80, 80])\nParameter Parameter containing:\ntensor([-0.0039,  0.0042,  0.0040,  0.0043,  0.0041, -0.0039, -0.0039,  0.0041,\n        -0.0039,  0.0040,  0.0041, -0.0039,  0.0046, -0.0035,  0.0041, -0.0039,\n        -0.0039,  0.0041, -0.0039,  0.0042,  0.0042,  0.0042,  0.0040,  0.0045,\n        -0.0038,  0.0041, -0.0040,  0.0041,  0.0041,  0.0041, -0.0039, -0.0011,\n        -0.0039,  0.0041,  0.0040, -0.0036, -0.0038,  0.0040, -0.0040,  0.0041,\n         0.0042,  0.0041, -0.0039, -0.0039, -0.0039,  0.0041, -0.0039,  0.0040,\n         0.0043,  0.0042, -0.0038,  0.0041, -0.0038,  0.0040, -0.0039, -0.0036,\n         0.0046, -0.0040,  0.0041,  0.0043,  0.0040,  0.0044,  0.0042,  0.0044,\n         0.0041, -0.0038,  0.0040,  0.0041, -0.0039, -0.0040,  0.0042, -0.0039,\n        -0.0029,  0.0041, -0.0032,  0.0042,  0.0042,  0.0042,  0.0040,  0.0041],\n       requires_grad=True) size: torch.Size([80])\nParameter Parameter containing:\ntensor([[-0.1555, -0.0800,  0.0808,  ..., -0.0747, -0.1116,  0.1269],\n        [-0.0693,  0.1670,  0.0717,  ...,  0.0359, -0.1560,  0.1878],\n        [-0.1245, -0.1747,  0.0911,  ...,  0.0932,  0.0126, -0.1581],\n        ...,\n        [ 0.1514,  0.0767, -0.0486,  ..., -0.1226, -0.1451,  0.1600],\n        [-0.1713, -0.0233,  0.1415,  ...,  0.1916, -0.1920, -0.1503],\n        [-0.1758,  0.1191, -0.1247,  ...,  0.1171, -0.1003, -0.0927]],\n       requires_grad=True) size: torch.Size([80, 80])\nParameter Parameter containing:\ntensor([-0.0040,  0.0040,  0.0040, -0.0041,  0.0040,  0.0040,  0.0040, -0.0040,\n         0.0040,  0.0040, -0.0040, -0.0040,  0.0040, -0.0040,  0.0040,  0.0040,\n         0.0040, -0.0040, -0.0040,  0.0040,  0.0045,  0.0040,  0.0040,  0.0040,\n         0.0040,  0.0040, -0.0040, -0.0040,  0.0040, -0.0040,  0.0040,  0.0040,\n         0.0040, -0.0040,  0.0040,  0.0040,  0.0040,  0.0040, -0.0040, -0.0040,\n         0.0040,  0.0040, -0.0040,  0.0040,  0.0040,  0.0040,  0.0040, -0.0040,\n        -0.0040,  0.0041,  0.0040, -0.0040, -0.0040, -0.0040, -0.0040,  0.0040,\n         0.0040,  0.0040, -0.0040, -0.0040, -0.0040, -0.0040,  0.0040, -0.0040,\n        -0.0040, -0.0040, -0.0040, -0.0040,  0.0040,  0.0040,  0.0040, -0.0040,\n        -0.0040,  0.0040, -0.0040,  0.0040, -0.0040,  0.0040, -0.0040, -0.0040],\n       requires_grad=True) size: torch.Size([80])\nParameter Parameter containing:\ntensor([[ 0.1374],\n        [-0.1196],\n        [-0.0456],\n        [ 0.0240],\n        [-0.1905],\n        [-0.0787],\n        [-0.0337],\n        [ 0.0671],\n        [-0.1811],\n        [-0.2639],\n        [ 0.0735],\n        [ 0.1965],\n        [-0.0726],\n        [ 0.1900],\n        [-0.0461],\n        [-0.1087],\n        [-0.2424],\n        [ 0.0499],\n        [ 0.2093],\n        [-0.2534],\n        [-0.0057],\n        [-0.1999],\n        [-0.1415],\n        [-0.1177],\n        [-0.0529],\n        [-0.0521],\n        [ 0.0343],\n        [ 0.1980],\n        [-0.2502],\n        [ 0.0437],\n        [-0.2435],\n        [-0.2124],\n        [-0.2543],\n        [ 0.2638],\n        [-0.1250],\n        [-0.2572],\n        [-0.0628],\n        [-0.2099],\n        [ 0.0589],\n        [ 0.0422],\n        [-0.0901],\n        [-0.1213],\n        [ 0.1504],\n        [-0.2011],\n        [-0.1248],\n        [-0.1642],\n        [-0.1149],\n        [ 0.2486],\n        [ 0.0842],\n        [-0.0264],\n        [-0.1564],\n        [ 0.1393],\n        [ 0.1602],\n        [ 0.2448],\n        [ 0.2043],\n        [-0.2284],\n        [-0.2138],\n        [-0.0930],\n        [ 0.1705],\n        [ 0.1779],\n        [ 0.1244],\n        [ 0.0781],\n        [-0.2000],\n        [ 0.1813],\n        [ 0.2294],\n        [ 0.0949],\n        [ 0.1024],\n        [ 0.2680],\n        [-0.2380],\n        [-0.2451],\n        [-0.1432],\n        [ 0.1054],\n        [ 0.0705],\n        [-0.1730],\n        [ 0.0702],\n        [-0.1064],\n        [ 0.0670],\n        [-0.2256],\n        [ 0.0900],\n        [ 0.2312]], requires_grad=True) size: torch.Size([80, 1])\nParameter Parameter containing:\ntensor([-0.0040], requires_grad=True) size: torch.Size([1])\nParameter Parameter containing:\ntensor([[ 6.5704e-02, -8.3361e-02, -1.8429e-02, -1.0730e-01, -3.6893e-02,\n          9.1811e-02,  1.3844e-01, -5.5724e-02,  1.5066e-01, -1.0341e-01,\n          6.8296e-02, -1.7142e-01, -1.8462e-01, -2.5871e-02, -1.4706e-01,\n         -4.6607e-02, -1.2160e-01, -4.1349e-02, -1.2138e-01,  2.0629e-01,\n          1.7627e-01, -1.6889e-01, -1.5946e-01,  1.3428e-01],\n        [-3.8909e-02,  1.5006e-01, -1.4212e-01,  1.9630e-01, -5.7393e-02,\n          1.2883e-02,  1.9906e-01,  1.0160e-02, -1.7113e-01, -1.6443e-01,\n          3.3022e-02, -1.5878e-01, -1.1939e-01, -1.4158e-01,  3.0890e-02,\n         -1.7113e-01, -6.9094e-03, -8.1347e-02, -1.8545e-01, -1.5549e-01,\n          7.8453e-02, -8.4284e-02, -5.8779e-02, -2.1078e-02],\n        [-3.6553e-02, -8.7991e-02,  1.6921e-01,  1.5305e-01, -1.9168e-01,\n         -1.4551e-01, -9.0551e-04,  1.4551e-01,  1.1107e-01, -6.2666e-02,\n         -1.1904e-01,  5.1948e-02, -2.1760e-02, -1.5010e-01, -1.6142e-01,\n         -1.4928e-01,  2.5385e-02, -1.2712e-01,  3.6160e-02,  1.9873e-01,\n          1.7401e-01,  1.4505e-01,  5.8088e-02, -1.2078e-03],\n        [-9.1402e-02,  6.4511e-02,  1.8828e-01,  7.7723e-02, -6.5196e-02,\n         -8.9931e-03, -1.8583e-01, -1.7226e-01,  1.7211e-01,  1.6890e-01,\n         -2.3160e-02,  1.3998e-01, -1.5144e-01, -5.9749e-02,  3.4666e-02,\n         -1.3377e-02, -6.0110e-02, -1.0811e-01, -6.9727e-02, -5.2302e-02,\n          5.3631e-02, -1.0409e-01, -5.9723e-02,  6.4665e-02],\n        [ 7.5674e-02, -5.7287e-02, -9.3929e-02, -1.2538e-01, -1.8974e-01,\n         -1.8896e-01,  1.0614e-01, -2.5546e-02, -1.2188e-01,  5.2873e-02,\n         -5.4067e-02, -2.3715e-02,  1.4851e-01,  1.3994e-03, -3.3063e-02,\n          1.2479e-01,  1.9991e-02, -1.8658e-01,  3.7021e-03, -1.0497e-01,\n         -9.5783e-02,  1.9328e-01, -8.3122e-02,  3.4181e-02],\n        [-1.3707e-02,  9.5147e-02, -1.7571e-01, -1.7688e-01,  8.1047e-02,\n         -7.2736e-03, -1.5487e-01,  1.0337e-01,  1.6023e-01,  1.6978e-01,\n          1.7390e-01, -1.8728e-01, -1.8608e-01, -1.8573e-01, -4.7041e-03,\n         -2.1206e-02,  1.0974e-01, -7.2966e-02, -1.1627e-01,  7.3095e-02,\n         -1.3741e-01, -4.0504e-02,  1.4115e-02,  1.8129e-01],\n        [-1.9814e-01, -1.3318e-01, -5.8998e-02, -1.5002e-01, -1.0864e-01,\n         -1.7461e-01,  7.3322e-02, -1.0690e-01, -6.3433e-04,  5.4790e-02,\n         -1.0553e-01, -5.7164e-02, -1.3749e-01, -1.4363e-02,  2.9413e-02,\n          1.6410e-01,  1.2856e-01, -1.7955e-01, -4.6246e-02,  1.4724e-01,\n         -1.8887e-01,  1.8227e-02,  1.9904e-01,  1.1703e-01],\n        [ 1.9578e-01, -7.0841e-02,  2.3883e-02,  9.8799e-03, -3.2928e-02,\n          5.5290e-02,  7.5642e-02,  5.6557e-02,  5.0873e-02, -1.4960e-01,\n          4.9019e-02, -1.1978e-01, -1.6823e-02,  1.2860e-01, -1.0145e-01,\n          8.7698e-02,  6.3465e-02, -1.0689e-01,  1.5142e-01, -2.9192e-02,\n          3.4667e-02, -6.3026e-02, -1.4001e-01,  7.0888e-02],\n        [-1.0388e-02,  6.3296e-02, -1.3008e-01,  2.9427e-02, -1.7101e-01,\n          5.1958e-02, -1.6547e-01,  1.0793e-02, -1.4400e-01, -1.7704e-01,\n         -9.8071e-02,  1.5377e-01,  1.1075e-02,  1.8555e-01,  1.2147e-01,\n          1.3557e-01,  1.6534e-01,  3.5430e-05, -9.7561e-02, -3.1179e-02,\n          8.1952e-02,  1.8873e-01, -1.5243e-01, -1.9253e-01],\n        [ 1.0000e-01, -2.2258e-02, -4.4564e-02, -1.0617e-01, -6.2968e-02,\n         -1.4626e-01,  4.8123e-02,  1.4067e-01, -1.3136e-01, -1.2748e-01,\n         -4.7852e-03, -1.6610e-01, -1.1285e-02,  4.0847e-02,  2.2395e-02,\n         -1.7689e-01,  1.7757e-01, -1.4042e-01, -4.0130e-02, -1.6589e-01,\n         -4.7337e-02,  1.5870e-01,  1.5900e-01,  1.1229e-01],\n        [-4.9251e-02,  1.3084e-01, -1.7032e-01, -1.2838e-01, -2.5584e-02,\n          5.3703e-02, -6.8416e-02, -1.2164e-01,  2.1691e-02,  6.1536e-02,\n          4.9195e-02,  1.1429e-01, -6.7106e-02, -1.3867e-01,  1.0823e-01,\n          1.4518e-01,  7.2036e-02, -1.6457e-01,  1.1045e-01, -1.9694e-01,\n          1.8656e-01,  3.5477e-03, -7.0794e-02, -1.3242e-01],\n        [ 1.3331e-01, -1.2658e-01,  4.4176e-02,  1.0210e-01, -1.2540e-01,\n          1.6173e-01, -1.0237e-01, -1.3946e-01, -9.7881e-02,  1.5368e-01,\n         -4.0882e-02,  1.8976e-01, -9.2678e-02, -1.3897e-01,  6.5772e-02,\n         -1.3596e-02, -4.7870e-02,  7.4942e-02,  1.4122e-01, -2.3756e-02,\n          1.8507e-01, -1.9395e-01,  1.9556e-01, -2.9656e-02],\n        [ 8.9293e-02,  1.1725e-02, -1.4164e-01,  3.1243e-02,  1.7604e-01,\n          1.0213e-01,  1.5669e-01,  1.4339e-01,  1.1497e-01,  9.8563e-02,\n         -1.9801e-01, -1.8418e-02,  8.7086e-02,  5.0726e-02,  5.0916e-02,\n          1.0325e-01, -1.7115e-01,  1.7073e-01,  1.8207e-01, -7.8198e-02,\n          1.7366e-01, -1.0252e-01, -1.9633e-01,  7.8362e-02],\n        [-1.7347e-01, -1.9560e-01,  1.0701e-01,  3.0754e-02, -1.1360e-01,\n         -1.0116e-01, -1.5444e-01, -7.4250e-02,  8.8731e-02,  1.9657e-01,\n          9.5565e-02, -8.8815e-03,  1.4713e-01, -5.6415e-02,  6.6858e-02,\n          4.6916e-02, -9.9855e-02, -9.1080e-02, -2.5688e-03, -4.3618e-02,\n         -1.0175e-01,  8.5136e-02,  6.6975e-02,  1.7619e-01],\n        [ 4.8489e-03, -9.0678e-02, -1.0587e-01, -2.7342e-02, -1.4726e-01,\n          1.2085e-01, -1.2891e-01, -4.6111e-02,  1.5577e-01, -1.8857e-01,\n          1.0043e-01, -2.8311e-02, -7.7616e-02,  1.2515e-01,  1.2908e-01,\n          1.8155e-01,  9.3307e-02, -1.3078e-01,  1.7114e-01,  9.9669e-02,\n          1.5133e-01,  7.5210e-02,  1.4446e-01,  9.8809e-02],\n        [ 1.7208e-01, -1.7402e-01, -9.9651e-04,  5.1544e-02,  3.8228e-02,\n         -8.8576e-02,  4.9478e-02,  1.5569e-01,  8.3556e-02,  1.1141e-01,\n         -7.1775e-02,  1.9933e-01, -1.6762e-02,  1.3662e-02,  1.5608e-01,\n         -9.7751e-02, -6.6806e-02, -1.6611e-01,  1.3243e-01, -1.8052e-01,\n          1.7596e-01,  1.6403e-01,  2.5783e-02, -3.2592e-02],\n        [ 2.8942e-02,  1.2918e-01, -2.1392e-02, -1.9286e-01,  4.4662e-02,\n          4.9622e-03,  1.5280e-01, -6.3522e-02,  4.0716e-03, -2.5682e-02,\n          2.8383e-02, -6.5538e-02, -5.6063e-03, -9.4909e-02,  4.0838e-02,\n          2.5993e-03, -1.2002e-01,  1.0303e-01,  7.2391e-02, -1.4208e-01,\n          1.1499e-01, -1.1499e-01, -1.2292e-01, -8.1323e-02],\n        [-1.3794e-01,  6.3172e-02, -1.4330e-01,  7.9664e-02, -2.2993e-02,\n          9.4017e-02,  1.2934e-02,  1.4514e-02, -6.8531e-02, -4.0985e-02,\n         -6.9323e-02,  3.1788e-03, -1.6912e-01, -1.6369e-01,  1.6174e-01,\n         -1.8928e-01, -1.6035e-01,  1.2401e-01, -1.6725e-01, -9.0281e-02,\n         -2.0377e-02, -1.7777e-01,  1.1201e-01, -1.2928e-01],\n        [-1.1570e-01,  1.8283e-01, -1.5489e-01, -2.8288e-03, -1.9113e-01,\n          1.1397e-01,  6.3321e-02, -7.1094e-02, -1.7797e-02,  6.8563e-02,\n         -6.5914e-02,  1.7300e-01, -1.4663e-01,  1.7109e-01, -1.9859e-01,\n         -4.5296e-02, -1.8356e-01,  3.0261e-02,  6.3624e-02,  3.9239e-02,\n          9.9534e-02, -7.7196e-02,  1.5487e-01, -6.0169e-02],\n        [ 9.6326e-02,  9.2189e-02,  1.5246e-01, -1.3794e-01, -1.6595e-01,\n         -9.3416e-02, -4.6988e-02,  2.0631e-01, -1.0085e-01, -4.6551e-02,\n          1.8815e-01,  3.9577e-02, -1.4182e-01, -6.4410e-02,  1.8307e-01,\n          5.4056e-02,  8.2983e-02, -1.0544e-01, -5.2679e-02, -1.9427e-01,\n          1.7743e-01, -1.8525e-01,  1.4915e-01, -9.5101e-02],\n        [-1.4890e-01,  4.0659e-02,  2.0396e-01, -1.5474e-01,  1.2013e-01,\n         -1.9692e-01, -2.9293e-02,  3.3743e-02, -5.7167e-02, -7.1388e-02,\n          1.4361e-01,  1.4317e-01, -4.2555e-02,  7.4679e-03,  1.9588e-01,\n         -9.3800e-02,  5.3870e-02, -1.5941e-01, -1.5303e-01, -1.6344e-04,\n         -8.2801e-02, -1.6016e-01, -1.9032e-01,  1.5548e-01],\n        [ 3.8923e-02,  7.3957e-02,  1.5085e-01, -1.7262e-01,  9.2345e-02,\n          8.7493e-03,  1.5433e-01, -1.9273e-01,  1.6686e-02,  1.9865e-01,\n          6.7036e-03, -1.6226e-01,  1.1369e-01, -1.3393e-01,  7.5574e-03,\n          9.4471e-02, -1.9203e-01, -7.7643e-02,  3.7413e-02, -1.3663e-01,\n         -1.9447e-01,  1.8961e-01,  1.0713e-01,  6.8932e-02],\n        [ 2.4658e-02,  1.4993e-01,  1.5457e-01,  1.6272e-02, -9.0153e-02,\n         -1.5346e-01,  1.4950e-02,  9.7661e-02,  1.3489e-01,  1.3319e-01,\n         -9.2564e-03,  8.3498e-02, -1.8572e-02,  1.3678e-01, -1.9955e-01,\n         -1.3003e-01,  1.1308e-01,  1.3453e-02,  2.0185e-01, -1.2109e-01,\n         -1.6270e-01,  9.7711e-02,  1.6093e-01,  7.8630e-02],\n        [-6.6651e-02, -1.2826e-01, -7.0352e-02,  4.2147e-02,  1.6935e-01,\n          2.0250e-01, -3.1412e-02,  6.8991e-02,  6.8969e-02, -1.6784e-01,\n         -8.6374e-03,  9.5180e-02,  1.5446e-01,  1.1997e-02,  9.5353e-02,\n          1.0228e-01,  1.8451e-01,  4.8889e-02, -1.4709e-01, -2.9681e-02,\n          1.9754e-01, -1.5404e-01,  1.0923e-01,  1.6824e-02]],\n       requires_grad=True) size: torch.Size([24, 24])\nParameter Parameter containing:\ntensor([-0.1910,  0.0811,  0.1455,  0.0138,  0.1839,  0.0787, -0.1811,  0.0367,\n        -0.0193,  0.1987, -0.1577,  0.0722, -0.0796,  0.0131, -0.1266, -0.0929,\n        -0.0004, -0.1918,  0.1750,  0.0292, -0.1211,  0.1984,  0.0782, -0.1252],\n       requires_grad=True) size: torch.Size([24])\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uHUoHNZoCGq",
        "outputId": "e9024273-c941-4881-a5c4-ce612deb01f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "# import itertools\n",
        "# optimizer = torch.optim.Adam(itertools.chain(net.parameters(), embed.parameters()), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "accumulation_steps = 100\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "loss_optm = []\n",
        "ep_range = 100\n",
        "for epoch in range(ep_range):\n",
        "    # print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
        "    for sample in range(n_train):\n",
        "      x_train_one,y_train_one = get_xy(sample)\n",
        "      print(x_train_one.shape)\n",
        "      print(y_train_one.shape)\n",
        "      net.train()\n",
        "      logits = net(G, x_train_one)\n",
        "      # loss = F.binary_cross_entropy(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
        "      # loss = F.mse_loss(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
        "      loss = F.mse_loss(logits, y_train_one) #/ accumulation_steps\n",
        "      loss.backward()\n",
        "\n",
        "      if ((sample+1)%accumulation_steps)==0:\n",
        "        optimizer.step() # update parameters of net\n",
        "        optimizer.zero_grad() # clear the psat gradient\n",
        "\n",
        "  # test for simple adaptive scheme\n",
        "    # if epoch > 10:\n",
        "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.15)\n",
        "    # if epoch > 10:\n",
        "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.04)\n",
        "    # if epoch > 20:\n",
        "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.03)\n",
        "    # if epoch > 30:\n",
        "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\n",
        "    # if epoch > 40:\n",
        "    #   optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "    # # Decay Learning Rate\n",
        "    # if epoch > 1:\n",
        "    #   scheduler.step()\n",
        "    \n",
        "    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))\n",
        "    loss_optm.append(loss.item())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\ntorch.Size([24, 1])\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m&lt;ipython-input-24-3b27ee9d5971&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_one\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 16\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0;31m# loss = F.binary_cross_entropy(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# loss = F.mse_loss(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m&lt;ipython-input-10-6aa228aa1cc8&gt;\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, inputs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# print(&#39;inputs data type:&#39;, inputs.data.type())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# print(inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 103\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;31m# h = torch.sigmoid(h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# print(h.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, weight)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_zero_in_degree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 236\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                     raise DGLError(&#39;There are 0-in-degree nodes in the graph, &#39;\n\u001b[1;32m    238\u001b[0m                                    \u001b[0;34m&#39;output for those nodes will be invalid. &#39;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36min_degrees\u001b[0;34m(self, v, etype)\u001b[0m\n\u001b[1;32m   3179\u001b[0m         \u001b[0metid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-&gt; 3181\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsttype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3182\u001b[0m         \u001b[0mv_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m&#39;v&#39;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3183\u001b[0m         \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/dgl/view.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ntype)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m&quot;&quot;&quot;Return the nodes.&quot;&quot;&quot;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mntid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typeid_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 43\u001b[0;31m         return F.copy_to(F.arange(0, self._graph._graph.number_of_nodes(ntid),\n\u001b[0m\u001b[1;32m     44\u001b[0m                                   dtype=self._graph.idtype),\n\u001b[1;32m     45\u001b[0m                          self._graph.device)\n",
            "\u001b[0;32m~/opt/anaconda3/envs/DL4OPF/lib/python3.8/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36marange\u001b[0;34m(start, stop, dtype)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 290\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrand_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSw7m9Tos9MH"
      },
      "source": [
        "ep_range1 = 20\n",
        "for epoch in range(ep_range1):\n",
        "    # print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
        "    for sample in range(n_train):\n",
        "      x_train_one,y_train_one=get_xy(sample)\n",
        "      net.train()\n",
        "      logits = net(G,I_bus, x_train_one)\n",
        "      # loss = F.binary_cross_entropy(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
        "      # loss = F.mse_loss(torch.sigmoid(logits), y_train_one) #/ accumulation_steps\n",
        "      loss = F.mse_loss(logits, y_train_one) #/ accumulation_steps\n",
        "      loss.backward()\n",
        "\n",
        "      if ((sample+1)%accumulation_steps)==0:\n",
        "        optimizer.step() # update parameters of net\n",
        "        optimizer.zero_grad() # clear the psat gradient\n",
        "\n",
        "    \n",
        "    print('Epoch %d | Loss: %.4f' % (epoch+ep_range, loss.item()))\n",
        "    loss_optm.append(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ0nLutzpyHX"
      },
      "source": [
        "## Optimization methods:\n",
        "**We need to incorporate batch size into the optimization step size for mini batches.** \n",
        "- **Rprop:** A gradient descent algorithm that only uses the signs of gradients to compute updates. It stands for Resilient Propagation and works well in many situations because it adapts the step size dynamically for each weight independently.\n",
        "- **Learning rate scheduling:** used with optimizers\n",
        "- **lr_scheduler.StepLR:** Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/\n",
        "- **lr_scheduler.CyclicLR:** Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR). The policy cycles the learning rate between two boundaries with a constant frequency. Cyclical learning rate policy changes the learning rate after every batch. step should be called after a batch has been used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfTSSX29R7jP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plot_idx = np.arange(np.size(loss_optm))\n",
        "plt.plot(plot_idx[3:-1],loss_optm[3:-1],lw=2,label='loss level')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF-gZIOko2Jd"
      },
      "source": [
        "## Step 4. Validation\n",
        "**Validate the trained model using the test set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uCp3fEEFGCv"
      },
      "source": [
        "When a model is trained, we can use the following method to evaluate the performance of the model on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrhVrVUb0d2t"
      },
      "source": [
        "# Generate one data pt. for testing the trained model\n",
        "def get_xy_test(index):\n",
        "    tempx=np.array([np.transpose(x_test)[index]])\n",
        "    x_train_one=torch.from_numpy(tempx).float()\n",
        "    x_train_one=x_train_one.transpose(0,1)\n",
        "\n",
        "    tempy=np.array([np.transpose(y_test)[index]])\n",
        "    y_train_one=torch.from_numpy(tempy).float()\n",
        "    y_train_one=y_train_one.transpose(0,1)\n",
        "\n",
        "    return x_train_one,y_train_one\n",
        "\n",
        "# generate torch y_train for concatenated obj\n",
        "y_test1 = torch.from_numpy(y_test)#.float()\n",
        "# expand into 3d tensor \n",
        "y_test1.unsqueeze_(-1)\n",
        "y_test1 = y_test1.expand(n_bus,n_test,1)\n",
        "y_test1 = y_test1.transpose(2,1)\n",
        "print(y_test1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PBICs8E51B"
      },
      "source": [
        "# model evaluation function\n",
        "def evaluate(model, g, features, labels, n, I):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      indices = torch.tensor(np.zeros((n_bus,1,n)))\n",
        "      for sample in range(n):\n",
        "        x_sample,y_sample=get_xy_test(sample)\n",
        "        logits = model(g, I, x_sample)\n",
        "        logp = logits\n",
        "        # logp = torch.sigmoid(logits)\n",
        "        # logp = F.log_softmax(logits, 1)\n",
        "        # _, indices1 = torch.max(logp, dim=1)\n",
        "        indices[:,:,sample] = logp.clone()\n",
        "\n",
        "      # correct = torch.sum(indices == labels)\n",
        "      # return correct.item() * 1.0 / len(labels)\n",
        "      return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5VvNfm_cFMD"
      },
      "source": [
        "print(x_test.shape)\n",
        "print(y_test1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrE4bhDc64fK"
      },
      "source": [
        "# make predictions\n",
        "indices = evaluate(net, G, x_test, y_test1,n_test, I_bus)\n",
        "# test_acc = evaluate(net, G, x_test, y_test1,n_test)\n",
        "# print(\"Epoch_last {:05d} | Loss {:.4f} | Test Acc {:.4f}\".format(epoch, loss.item(), test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7QRkoh8b1cm"
      },
      "source": [
        "y_test0 = y_test1.numpy().copy()\n",
        "y_pred0 = indices.numpy().copy()\n",
        "\n",
        "L_infty_err = []\n",
        "L1_err = []\n",
        "for i in range(n_test):\n",
        "  L_infty_err.append(np.max(np.abs(y_test0[:,:,i]-y_pred0[:,:,i])))\n",
        "  L1_err.append(np.sum(np.abs(y_test0[:,:,i]-y_pred0[:,:,i])))\n",
        "print('L_infty mean: ',np.mean(L_infty_err))\n",
        "print('L_1 mean: ',np.mean(L1_err))\n",
        " \n",
        "val, idx = min((val, idx) for (idx, val) in enumerate(L_infty_err))\n",
        "print(val,idx)\n",
        "# print('L_inf sample: \\n',y_test[:,:,idx])\n",
        "# print(y_pred[:,:,idx])\n",
        "val1, idx1 = min((val, idx) for (idx, val) in enumerate(L1_err))\n",
        "print(val1,idx1)\n",
        "# print('L1 sample: \\n',y_test[:,:,idx1])\n",
        "# print(y_pred[:,:,idx1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW9qX0nGgoS_"
      },
      "source": [
        "print(load_data[0:n_bus,:].shape)\n",
        "print(y0[0:n_bus,0:n_sample].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pQ1v0b58NRH"
      },
      "source": [
        "# Save the predictions for other training/evaluation jobs\n",
        "\n",
        "import pickle\n",
        "import pprint\n",
        "from os import path\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "def save_dataset(test_case, dataset):\n",
        "    file_name = test_case.split('.')[0]\n",
        "    file_path = 'drive/My Drive/gnn/numerical_results/'\n",
        "    file_dir = file_path + file_name + '.pickle'\n",
        "    outfile = open(file_dir, 'wb')\n",
        "    pickle.dump(dataset, outfile)\n",
        "    outfile.close()\n",
        "\n",
        "def get_xy_eval(index):\n",
        "    tempx=np.array([np.transpose(load_data[0:n_bus,:])[index]])\n",
        "    x_train_one=torch.from_numpy(tempx).float()\n",
        "    x_train_one=x_train_one.transpose(0,1)\n",
        "\n",
        "    return x_train_one\n",
        "\n",
        "def model_eval(model, g, features, n, I):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      indices = torch.tensor(np.zeros((n_bus,1,n)))\n",
        "      for sample in range(n):\n",
        "        x_sample=get_xy_eval(sample)\n",
        "        logits = model(g, I, x_sample)\n",
        "        logp = logits\n",
        "        indices[:,:,sample] = logp.clone()\n",
        "\n",
        "      return indices\n",
        "\n",
        "indices = model_eval(net, G, load_data[0:n_bus,:], n_sample, I_bus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdH_Svt5js05"
      },
      "source": [
        "# generation prediction by GNN model\n",
        "print(indices.shape)\n",
        "gen_pred_norm = indices.numpy().copy()\n",
        "\n",
        "y0[j,i] = np.divide(gen_exact[j,i]-gen_low_limit[j],gen_up_limit[j]-gen_low_limit[j])\n",
        "\n",
        "gen_pred = np.zeros((n_bus,n_sample))\n",
        "for i in range(n_sample):\n",
        "  for j in range(n_bus):\n",
        "    gen_pred[j,i] = indices[j,0,i] * (gen_up_limit[j]-gen_low_limit[j]) + gen_low_limit[j]\n",
        "\n",
        "dataset = {'pred': gen_pred}\n",
        "# print(dataset)\n",
        "filename = 'GNN_24bus_gen_prediction_copy_new'\n",
        "save_dataset(filename, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ5hVfqjde3z"
      },
      "source": [
        "for i in range(10):\n",
        "  print(np.sum(x_train[:,i]),np.sum(gen_pred[:,i]))\n",
        "# print(np.sum(gen_pred[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h31WYc4LtTG"
      },
      "source": [
        "# Evaluate the prediction accuracy by relative error\n",
        "acc_threshold1 = 0.05\n",
        "acc_threshold = 0.1\n",
        "\n",
        "acc_count = 0\n",
        "acc_count1 = 0\n",
        "for i in range(24):\n",
        "  if np.abs(y_test0[i,:,idx]) > 0:\n",
        "    if np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx])/np.abs(y_test0[i,:,idx]) < acc_threshold or np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx]) < acc_threshold1:\n",
        "        acc_count = acc_count+1\n",
        "    if np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1])/np.abs(y_test0[i,:,idx1]) < acc_threshold or np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1]) < acc_threshold1:\n",
        "        acc_count1 = acc_count1+1\n",
        "  else:\n",
        "    if np.abs(y_test0[i,:,idx]-y_pred0[i,:,idx]) < acc_threshold1:\n",
        "        acc_count = acc_count+1\n",
        "    if np.abs(y_test0[i,:,idx1]-y_pred0[i,:,idx1]) < acc_threshold1:\n",
        "        acc_count1 = acc_count1+1\n",
        "print('most accurate L_inf: ',acc_count,'  L_1: ',acc_count1)\n",
        "\n",
        "\n",
        "acc_test = np.zeros(y_test0.shape[0])\n",
        "for j in range(y_test0.shape[0]):\n",
        "  acc_count = 0\n",
        "  for i in range(24):\n",
        "    if np.abs(y_test0[i,:,j]) > 0:\n",
        "      if np.abs(y_test0[i,:,j]-y_pred0[i,:,j])/np.abs(y_test0[i,:,j]) < acc_threshold or np.abs(y_test0[i,:,j]-y_pred0[i,:,j]) < acc_threshold1:\n",
        "          acc_count = acc_count+1\n",
        "    else:\n",
        "      if np.abs(y_test0[i,:,j]-y_pred0[i,:,j]) < acc_threshold1:\n",
        "          acc_count = acc_count+1\n",
        "  acc_test[j] = acc_count\n",
        "print('Mean accuracy: ',np.mean(acc_test)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzHeOYpbIZ41"
      },
      "source": [
        "\n",
        "# for i in range(3):\n",
        "  # print('Prediction:',indices[:,:,i].transpose(0,1))\n",
        "  # print('Ture label:',y_test1[:,:,i].transpose(0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu4vxBiiG7IN"
      },
      "source": [
        "## Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZIQUKv3G42U"
      },
      "source": [
        "import math\n",
        "import seaborn as sns\n",
        "def result_reshape(data):\n",
        "    result_dim = math.ceil(math.sqrt(len(data)))\n",
        "    reshaped_data = np.zeros((result_dim, result_dim))\n",
        "\n",
        "    for i in range(result_dim):\n",
        "        for j in range(result_dim):\n",
        "            try:\n",
        "                reshaped_data[i][j] = data[result_dim * i + j]\n",
        "            except IndexError:\n",
        "                reshaped_data[i][j] = -1\n",
        "    return reshaped_data\n",
        "\n",
        "\n",
        "def test_vs_pred(y_test, y_pred,  data_idx, test_case):\n",
        "    y_test0 = y_test[:,:,data_idx]\n",
        "    y_pred0 = y_pred[:,:,data_idx]\n",
        "    y_test_reshaped = result_reshape(y_test0)\n",
        "    y_pred_reshaped = result_reshape(y_pred0)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
        "\n",
        "    fig.suptitle('Active Constraints Distribution: ' + test_case.split('.')[0], size=19, y=0.88)\n",
        "    axes[0].set_title('y_test', size=15, y=1.03)\n",
        "    axes[1].set_title('y_pred', size=15, y=1.03)\n",
        "    # axes[2].set_title('y_pred_binary', size=15, y=1.03)\n",
        "\n",
        "    sns.heatmap(y_test_reshaped,\n",
        "                xticklabels=False,\n",
        "                yticklabels=False,\n",
        "                cbar_kws={'ticks': [-1, 0, 1], 'shrink': .75},\n",
        "                square=True,\n",
        "                ax=axes[0])\n",
        "\n",
        "    sns.heatmap(y_pred_reshaped,\n",
        "                xticklabels=False,\n",
        "                yticklabels=False,\n",
        "                cbar_kws={'ticks': [-1, 0, 1], 'shrink': .75},\n",
        "                square=True,\n",
        "                ax=axes[1])\n",
        "    \n",
        "\n",
        "    fig.show()\n",
        "    # file_dir = path.join('drive/My Drive/OPF_Porject_EE394V_SPR2020-master/codes/experiments/figures/', test_case.split('.')[0] + '.png')\n",
        "    # fig.savefig(file_dir, format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrfl_miqWLip"
      },
      "source": [
        "print(y_test1[:,:,1].transpose(0,1))\n",
        "print(indices[:,:,1].transpose(0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNlT68rcHGHV"
      },
      "source": [
        "# y_test1.resize_((n_bus+n_line,n_test))\n",
        "# indices_int.resize_((n_bus+n_line,n_test))\n",
        "# indices.resize_((n_bus+n_line,n_test))\n",
        "\n",
        "test_cases = [\n",
        "    'pglib_opf_case24_ieee_rts.pickle', \n",
        "]\n",
        "\n",
        "data_idx = [7,10,33,55,64,78,96]\n",
        "data_idx = np.arange(10)\n",
        "# test_vs_pred(y_test, y_pred, data_idx, test_cases[case_idx])\n",
        "for i in range(len(data_idx)):\n",
        "  test_vs_pred(y_test1, indices, data_idx[i], test_cases[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}